{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import preprocessor as p\n",
    "import re\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tag.perceptron import PerceptronTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_text = pd.read_csv('/Users/matthewcassi/Documents/nhl_sentiment_working/sentiment_data/training_sentiment.csv', encoding='ISO-8859-1', header=None)\n",
    "testing_text = pd.read_csv('/Users/matthewcassi/Documents/nhl_sentiment_working/sentiment_data/testing_sentiment.csv', encoding='ISO-8859-1', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3                4  \\\n",
       "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                   5  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_text.columns = ['sentiment','id','date','query','user','text']\n",
    "testing_text.columns = ['sentiment','id','date','query','user','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date     query  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_text = training_text[['sentiment','text']]\n",
    "testing_text = testing_text[['sentiment','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_text = testing_text[testing_text['sentiment'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      4\n",
       "1      4\n",
       "2      4\n",
       "3      4\n",
       "4      4\n",
       "5      4\n",
       "6      0\n",
       "7      4\n",
       "8      4\n",
       "9      4\n",
       "11     0\n",
       "12     4\n",
       "13     4\n",
       "14     0\n",
       "15     4\n",
       "16     0\n",
       "17     4\n",
       "18     0\n",
       "19     4\n",
       "20     4\n",
       "21     4\n",
       "22     4\n",
       "23     4\n",
       "24     4\n",
       "25     4\n",
       "26     4\n",
       "27     4\n",
       "28     4\n",
       "29     4\n",
       "32     4\n",
       "      ..\n",
       "457    0\n",
       "458    0\n",
       "461    0\n",
       "462    0\n",
       "463    4\n",
       "464    0\n",
       "467    4\n",
       "468    0\n",
       "469    4\n",
       "470    4\n",
       "471    4\n",
       "474    0\n",
       "476    4\n",
       "477    4\n",
       "478    4\n",
       "479    4\n",
       "480    0\n",
       "481    0\n",
       "482    0\n",
       "484    0\n",
       "485    0\n",
       "487    4\n",
       "489    4\n",
       "490    0\n",
       "491    4\n",
       "492    4\n",
       "494    0\n",
       "495    4\n",
       "496    0\n",
       "497    0\n",
       "Name: sentiment, Length: 359, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_text['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_dict = {0:0, 4:1}\n",
    "\n",
    "training_text['sentiment'] = training_text['sentiment'].map(map_dict)\n",
    "testing_text['sentiment'] = testing_text['sentiment'].map(map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def html_fix(string):\n",
    "    string = BeautifulSoup(string, 'lxml').get_text()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_text['text'] = training_text['text'].apply(html_fix)\n",
    "testing_text['text'] = testing_text['text'].apply(html_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# row wise function to remove URLs and emojis. takes a row and a column\n",
    "def remove_urls(row, col):\n",
    "    # set tweet preprocessing to remove emojis and URLs\n",
    "    p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION, p.OPT.HASHTAG)\n",
    "    \n",
    "    # remove emojis and URLs from the column\n",
    "    if type(row[col]) == str:\n",
    "        return p.clean(row[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_text['text'] = training_text.apply(remove_urls, axis=1, col='text')\n",
    "testing_text['text'] = testing_text.apply(remove_urls, axis=1, col='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_text['text'] = training_text['text'].str.lower()\n",
    "testing_text['text'] = testing_text['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace the rt with nothing at the front of all tweet_1 columns\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])rt(?![a-z])', '', case=False)\n",
    "# replace hashtag with nothing\n",
    "training_text['text'] = training_text['text'].str.replace('#', '', case=False)\n",
    "# replace u/U with you\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])u(?![a-z])', 'you', case=False) \n",
    "# replace r with are\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])r(?![a-z])', 'are', case=False)\n",
    "# replace r with are\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])r(?![a-z])', 'are', case=False)\n",
    "# replace r with are\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])r(?![a-z])', 'are', case=False)\n",
    "# replace thx with thanks\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])thx(?![a-z])', 'thanks', case=False)\n",
    "# replace ur with your\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])ur(?![a-z])', 'your', case=False)\n",
    "# replace bc with because\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])bc(?![a-z])', 'because', case=False)\n",
    "# replace abt with about\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])abt(?![a-z])', 'about', case=False)\n",
    "# replace txt with tweet_1\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])txt(?![a-z])', 'tweet_1', case=False)\n",
    "# replace fb with facebook\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])fb(?![a-z])', 'facebook', case=False)\n",
    "# replace w with with\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])w(?![a-z])', 'with', case=False)\n",
    "# replace b4 with before\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])b4(?![a-z])', 'before', case=False)\n",
    "# replace ast with assist\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])ast(?![a-z])', 'assist', case=False)\n",
    "# replace tgif with thank god its friday\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])tgif(?![a-z])', 'thank god its friday', case=False)\n",
    "# replace ily with i love you\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])ily(?![a-z])', 'i love you', case=False)\n",
    "# replace irl with in real life\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])irl(?![a-z])', 'in real life', case=False)\n",
    "# replace idk with i dont know\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])idk(?![a-z])', 'i dont know', case=False)\n",
    "# replace ftw with for the win\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])ftw(?![a-z])', 'for the win', case=False)\n",
    "# replace idc with i dont care\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])idc(?![a-z])', 'i dont care', case=False)\n",
    "# replace tbt with throwback thursday\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])tbt(?![a-z])', 'throwback thursday', case=False)\n",
    "# replace tbh with to be honest\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])tbh(?![a-z])', 'to be honest', case=False)\n",
    "# replace tfw with that face when\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])tfw(?![a-z])', 'that face when', case=False)\n",
    "# replace qotd with quote of the day\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])qotd(?![a-z])', 'quote of the day', case=False)\n",
    "# replace bff with best friends forever\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])bff(?![a-z])', 'best friends forever', case=False)\n",
    "# replace jk with just kidding\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])jk(?![a-z])', 'just kidding', case=False)\n",
    "# replace smh with shaking my head\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])smh(?![a-z])', 'shaking my head', case=False)\n",
    "# replace btw with by the way\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])btw(?![a-z])', 'by the way', case=False)\n",
    "# replace imo with in my opinion\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])imo(?![a-z])', 'in my opinion', case=False)\n",
    "# replace imho with in my honest opinion\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])imho(?![a-z])', 'in my honest opinion', case=False)\n",
    "# replace icymi with in case you missed it\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])icymi(?![a-z])', 'in case you missed it', case=False)\n",
    "# replace lol with laugh out loud\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])lol(?![a-z])', 'laugh out loud', case=False)\n",
    "# replace fwiw with for what its worth\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])fwiw(?![a-z])', 'for what its worth', case=False)\n",
    "# replace afaik with as far as i know\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])afaik(?![a-z])', 'as far as i know', case=False)\n",
    "# replace gg with good game\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])gg(?![a-z])', 'good game', case=False)\n",
    "# replace fyi with for your information\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])fyi(?![a-z])', 'for your information', case=False)\n",
    "# replace num with number\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])num(?![a-z])', 'number', case=False)\n",
    "# replace omg with oh my god\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])omg(?![a-z])', 'oh my god', case=False)\n",
    "# replace omfg with oh my fucking god\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])omfg(?![a-z])', 'oh my fucking god', case=False)\n",
    "# replace asap with as soon as possible\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])asap(?![a-z])', 'as soon as possible', case=False)\n",
    "# replace til with today i learned\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])til(?![a-z])', 'today i learned', case=False)\n",
    "# replace lmao with laugh my ass off\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])lmao(?![a-z])', 'laugh my ass off', case=False)\n",
    "# replace lmfao with laugh my fucking ass off\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])lmfao(?![a-z])', 'laugh my fucking ass off', case=False)\n",
    "# replace dm with direct message\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])dm(?![a-z])', 'direct message', case=False)\n",
    "# replace rofl with rolling on the floor laughing\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])rofl(?![a-z])', 'rolling on the floor laughing', case=False)\n",
    "# replace fomo with fear of missing out\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])fomo(?![a-z])', 'fear of missing out', case=False)\n",
    "# replace orly with oh really\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])orly(?![a-z])', 'oh really', case=False)\n",
    "# replace eli5 with explain like im five\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])eli5(?![a-z])', 'explain like im five', case=False)\n",
    "# replace tmi with too much information\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])tmi(?![a-z])', 'too much information', case=False)\n",
    "# replace &amp; with and\n",
    "training_text['text'] = training_text['text'].str.replace('&amp;', 'and', case=False)\n",
    "# replace yrs with years\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])yrs(?![a-z])', 'years', case=False)\n",
    "# replace yr with year\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])yr(?![a-z])', 'year', case=False)\n",
    "# replace pt with point\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])pt(?![a-z])', 'point', case=False)\n",
    "# replace pts with points\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])pts(?![a-z])', 'points', case=False)\n",
    "# replace - with ' '\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])pts(?![a-z])', 'points', case=False)\n",
    "# replace % with percent\n",
    "training_text['text'] = training_text['text'].str.replace('%', 'percent', case=False)\n",
    "# replace fireav with fire av\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])fireav(?![a-z])', 'fire av', case=False)\n",
    "# replace vs with versus\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])pts(?![a-z])', 'points', case=False)\n",
    "# replace ir with injured reserve\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])ir(?![a-z])', 'injured reserve', case=False)\n",
    "# replace gp with game played\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])gp(?![a-z])', 'game played', case=False)\n",
    "# replace pts with points\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])pts(?![a-z])', 'points', case=False)\n",
    "# replace vip with very important person\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])vip(?![a-z])', 'very important person', case=False)\n",
    "# replace pei with prince edward island\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])pei(?![a-z])', 'prince edward island', case=False)\n",
    "# replace hof with hall of fame\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])hof(?![a-z])', 'hall of fame', case=False)\n",
    "# replace msg with madison square garden\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])msg(?![a-z])', 'madison square garden', case=False)\n",
    "# replace #msg with madison square garden\n",
    "training_text['text'] = training_text['text'].str.replace('#msg', 'madison square garden', case=False)\n",
    "# replace pls with please\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])pls(?![a-z])', 'please', case=False)\n",
    "\n",
    "#contractions\n",
    "training_text['text'] = training_text['text'].str.replace(r\"won't\", \"will not\", case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r\"can\\'t\", \"can not\", case=False)\n",
    "\n",
    "# general\n",
    "training_text['text'] = training_text['text'].str.replace(r\"n\\'t\", \" not\", case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r\"\\'re\", \" are\", case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r\"\\'s\", \" is\", case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r\"\\'d\", \" would\", case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r\"\\'ll\", \" will\", case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r\"\\'t\", \" not\", case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r\"\\'ve\", \" have\", case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r\"\\'m\", \" am\", case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace the rt with nothing at the front of all tweet_1 columns\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])rt(?![a-z])', '', case=False)\n",
    "# replace hashtag with nothing\n",
    "testing_text['text'] = testing_text['text'].str.replace('#', '', case=False)\n",
    "# replace u/U with you\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])u(?![a-z])', 'you', case=False) \n",
    "# replace r with are\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])r(?![a-z])', 'are', case=False)\n",
    "# replace r with are\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])r(?![a-z])', 'are', case=False)\n",
    "# replace r with are\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])r(?![a-z])', 'are', case=False)\n",
    "# replace thx with thanks\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])thx(?![a-z])', 'thanks', case=False)\n",
    "# replace ur with your\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])ur(?![a-z])', 'your', case=False)\n",
    "# replace bc with because\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])bc(?![a-z])', 'because', case=False)\n",
    "# replace abt with about\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])abt(?![a-z])', 'about', case=False)\n",
    "# replace txt with tweet_1\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])txt(?![a-z])', 'tweet_1', case=False)\n",
    "# replace fb with facebook\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])fb(?![a-z])', 'facebook', case=False)\n",
    "# replace w with with\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])w(?![a-z])', 'with', case=False)\n",
    "# replace b4 with before\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])b4(?![a-z])', 'before', case=False)\n",
    "# replace ast with assist\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])ast(?![a-z])', 'assist', case=False)\n",
    "# replace tgif with thank god its friday\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])tgif(?![a-z])', 'thank god its friday', case=False)\n",
    "# replace ily with i love you\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])ily(?![a-z])', 'i love you', case=False)\n",
    "# replace irl with in real life\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])irl(?![a-z])', 'in real life', case=False)\n",
    "# replace idk with i dont know\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])idk(?![a-z])', 'i dont know', case=False)\n",
    "# replace ftw with for the win\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])ftw(?![a-z])', 'for the win', case=False)\n",
    "# replace idc with i dont care\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])idc(?![a-z])', 'i dont care', case=False)\n",
    "# replace tbt with throwback thursday\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])tbt(?![a-z])', 'throwback thursday', case=False)\n",
    "# replace tbh with to be honest\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])tbh(?![a-z])', 'to be honest', case=False)\n",
    "# replace tfw with that face when\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])tfw(?![a-z])', 'that face when', case=False)\n",
    "# replace qotd with quote of the day\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])qotd(?![a-z])', 'quote of the day', case=False)\n",
    "# replace bff with best friends forever\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])bff(?![a-z])', 'best friends forever', case=False)\n",
    "# replace jk with just kidding\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])jk(?![a-z])', 'just kidding', case=False)\n",
    "# replace smh with shaking my head\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])smh(?![a-z])', 'shaking my head', case=False)\n",
    "# replace btw with by the way\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])btw(?![a-z])', 'by the way', case=False)\n",
    "# replace imo with in my opinion\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])imo(?![a-z])', 'in my opinion', case=False)\n",
    "# replace imho with in my honest opinion\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])imho(?![a-z])', 'in my honest opinion', case=False)\n",
    "# replace icymi with in case you missed it\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])icymi(?![a-z])', 'in case you missed it', case=False)\n",
    "# replace lol with laugh out loud\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])lol(?![a-z])', 'laugh out loud', case=False)\n",
    "# replace fwiw with for what its worth\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])fwiw(?![a-z])', 'for what its worth', case=False)\n",
    "# replace afaik with as far as i know\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])afaik(?![a-z])', 'as far as i know', case=False)\n",
    "# replace gg with good game\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])gg(?![a-z])', 'good game', case=False)\n",
    "# replace fyi with for your information\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])fyi(?![a-z])', 'for your information', case=False)\n",
    "# replace num with number\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])num(?![a-z])', 'number', case=False)\n",
    "# replace omg with oh my god\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])omg(?![a-z])', 'oh my god', case=False)\n",
    "# replace omfg with oh my fucking god\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])omfg(?![a-z])', 'oh my fucking god', case=False)\n",
    "# replace asap with as soon as possible\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])asap(?![a-z])', 'as soon as possible', case=False)\n",
    "# replace til with today i learned\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])til(?![a-z])', 'today i learned', case=False)\n",
    "# replace lmao with laugh my ass off\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])lmao(?![a-z])', 'laugh my ass off', case=False)\n",
    "# replace lmfao with laugh my fucking ass off\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])lmfao(?![a-z])', 'laugh my fucking ass off', case=False)\n",
    "# replace dm with direct message\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])dm(?![a-z])', 'direct message', case=False)\n",
    "# replace rofl with rolling on the floor laughing\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])rofl(?![a-z])', 'rolling on the floor laughing', case=False)\n",
    "# replace fomo with fear of missing out\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])fomo(?![a-z])', 'fear of missing out', case=False)\n",
    "# replace orly with oh really\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])orly(?![a-z])', 'oh really', case=False)\n",
    "# replace eli5 with explain like im five\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])eli5(?![a-z])', 'explain like im five', case=False)\n",
    "# replace tmi with too much information\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])tmi(?![a-z])', 'too much information', case=False)\n",
    "# replace &amp; with and\n",
    "testing_text['text'] = testing_text['text'].str.replace('&amp;', 'and', case=False)\n",
    "# replace yrs with years\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])yrs(?![a-z])', 'years', case=False)\n",
    "# replace yr with year\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])yr(?![a-z])', 'year', case=False)\n",
    "# replace pt with point\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])pt(?![a-z])', 'point', case=False)\n",
    "# replace pts with points\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])pts(?![a-z])', 'points', case=False)\n",
    "# replace - with ' '\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])pts(?![a-z])', 'points', case=False)\n",
    "# replace % with percent\n",
    "testing_text['text'] = testing_text['text'].str.replace('%', 'percent', case=False)\n",
    "# replace fireav with fire av\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])fireav(?![a-z])', 'fire av', case=False)\n",
    "# replace vs with versus\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])pts(?![a-z])', 'points', case=False)\n",
    "# replace ir with injured reserve\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])ir(?![a-z])', 'injured reserve', case=False)\n",
    "# replace gp with game played\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])gp(?![a-z])', 'game played', case=False)\n",
    "# replace pts with points\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])pts(?![a-z])', 'points', case=False)\n",
    "# replace vip with very important person\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])vip(?![a-z])', 'very important person', case=False)\n",
    "# replace pei with prince edward island\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])pei(?![a-z])', 'prince edward island', case=False)\n",
    "# replace hof with hall of fame\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])hof(?![a-z])', 'hall of fame', case=False)\n",
    "# replace msg with madison square garden\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])msg(?![a-z])', 'madison square garden', case=False)\n",
    "# replace #msg with madison square garden\n",
    "testing_text['text'] = testing_text['text'].str.replace('#msg', 'madison square garden', case=False)\n",
    "# replace pls with please\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])pls(?![a-z])', 'please', case=False)\n",
    "\n",
    "#contractions\n",
    "testing_text['text'] = testing_text['text'].str.replace(r\"won't\", \"will not\", case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r\"can\\'t\", \"can not\", case=False)\n",
    "\n",
    "# general\n",
    "testing_text['text'] = testing_text['text'].str.replace(r\"n\\'t\", \" not\", case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r\"\\'re\", \" are\", case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r\"\\'s\", \" is\", case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r\"\\'d\", \" would\", case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r\"\\'ll\", \" will\", case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r\"\\'t\", \" not\", case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r\"\\'ve\", \" have\", case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r\"\\'m\", \" am\", case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emojis(row, col):\n",
    "    text = row[col]\n",
    "    if type(row[col]) == str:\n",
    "        text = re.sub(r'[^a-zA-Z ]+', '', row[col])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_text['text'] = training_text.apply(emojis, axis=1, col='text')\n",
    "testing_text['text'] = testing_text.apply(emojis, axis=1, col='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>awww that is a bummer you shoulda got david c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>no it is not behaving at all i am mad why am i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0   awww that is a bummer you shoulda got david c...\n",
       "1          0  is upset that he can not update his facebook b...\n",
       "2          0  i dived many times for the ball managed to sav...\n",
       "3          0     my whole body feels itchy and like its on fire\n",
       "4          0  no it is not behaving at all i am mad why am i..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>i loooooooovvvvvveee my kindle not that the dx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>reading my kindle love it lee childs is good read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ok first assesment of the it fucking rocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>you will love your kindle i have had mine for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>fair enough but i have the kindle and i think ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          1  i loooooooovvvvvveee my kindle not that the dx...\n",
       "1          1  reading my kindle love it lee childs is good read\n",
       "2          1         ok first assesment of the it fucking rocks\n",
       "3          1  you will love your kindle i have had mine for ...\n",
       "4          1  fair enough but i have the kindle and i think ..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])machinehead(?![a-z])', 'machine head', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])badgood(?![a-z])', 'bad good', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])nightce(?![a-z])', 'night', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])laaammmeeee(?![a-z])', 'lame', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])lifejesus(?![a-z])', 'life jesus', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])acquiescin(?![a-z])', 'acquiescing', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])ammoxxx(?![a-z])', '', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])daddii(?![a-z])', 'daddy', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])fastits(?![a-z])', 'fast its', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])iamjonathancook(?![a-z])', 'i am jonathan cook', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])thtt(?![a-z])', 'that', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])ihazfoodinmytummy(?![a-z])', 'i have food in my stomach', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])okreal(?![a-z])', 'ok real', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])withdrawnunity(?![a-z])', 'withdrawn unity', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])schbag(?![a-z])', 'bag', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])aaaaaaaaaahhhhhhhh(?![a-z])', 'ah', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])taboooo(?![a-z])', 'taboo', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])onechancenoend(?![a-z])', 'one chance no end', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])studyso(?![a-z])', 'study so', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])biitch(?![a-z])', 'bitch', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])quotooh(?![a-z])', 'quote', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])yeahmonkey(?![a-z])', 'yeah monkey', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])nightandstill(?![a-z])', 'night and still', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])rightp(?![a-z])', 'right', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])lalajenny(?![a-z])', 'lala jenny', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])alrightt(?![a-z])', 'all right', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])tradespacers(?![a-z])', 'trade spacers', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])hotdof(?![a-z])', 'hotdog', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])watchis(?![a-z])', 'watches', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])poppystephpage(?![a-z])', 'poppy steph page', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])reeaaaally(?![a-z])', 'really', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])kikkoanddaryl(?![a-z])', 'kikko and daryl', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])npatience(?![a-z])', 'patience', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])studyingmeh(?![a-z])', 'studying', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])chillinmymoodiamok(?![a-z])', 'chilling my mood i amok', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])mwahahahahohononono(?![a-z])', 'laughing no', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])tiredsee(?![a-z])', 'tired see', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])suckin(?![a-z])', 'sucking', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])quottee(?![a-z])', 'quote', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])nowanother(?![a-z])', 'now another', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])redpath(?![a-z])', 'red path', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])straightiner(?![a-z])', 'straightener', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])tennantcast(?![a-z])', 'tennant cast', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])tremorsthis(?![a-z])', 'tremors this', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])jokerjax(?![a-z])', 'joker jax', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])twiiiiter(?![a-z])', 'twitter', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])isdidnt(?![a-z])', 'is didnt', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])badabing(?![a-z])', 'easy', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])andbeergnite(?![a-z])', 'and beer goodnight', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])davepts(?![a-z])', 'dave points', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])timbeeeeeeeeeeerinsert(?![a-z])', 'timber insert', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])strssd(?![a-z])', 'stressed', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])tweeped(?![a-z])', '', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])windshieldroof(?![a-z])', 'windshield roof', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])codeshare(?![a-z])', 'code share', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])twittercut(?![a-z])', 'twitter cut', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])skincolor(?![a-z])', 'skin color', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])phoneeeeeeeeeeeeee(?![a-z])', 'phone', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])assnoles(?![a-z])', 'assholes', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])pleasecloseyoureyes(?![a-z])', 'please close your eyes', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])yooooooooooou(?![a-z])', 'you', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])blueskied(?![a-z])', 'blue skied', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])entrepenuercom(?![a-z])', '', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])freezinggg(?![a-z])', 'freezing', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])rainfuelled(?![a-z])', 'rain fuelled', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])tomorrroow(?![a-z])', 'tomorrow', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])boredthe(?![a-z])', 'bored the', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])mcspaming(?![a-z])', 'mcspaming', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])toywell(?![a-z])', 'toy well', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])nvrmd(?![a-z])', 'nevermind', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])didwhats(?![a-z])', 'did whats', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])ohyes(?![a-z])', 'oh yes', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])toogala(?![a-z])', 'too gala', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])scarletbe(?![a-z])', 'scarlet be', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])listenning(?![a-z])', 'listening', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])thothat(?![a-z])', 'though that', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])sleepnightshift(?![a-z])', 'sleeping night shift', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])universitis(?![a-z])', 'universities', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])beein(?![a-z])', 'beeing', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])frushi(?![a-z])', '', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])forgotgod(?![a-z])', 'forgot god', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])goim(?![a-z])', 'going', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])bluelillyscouk(?![a-z])', 'blue lilly scouk', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])sighrest(?![a-z])', 'sigh rest', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])conflicing(?![a-z])', 'conflicting', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])tredtwo(?![a-z])', 'tred two', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])withwho(?![a-z])', 'with who', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])somethingyoud(?![a-z])', 'something you would', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])niecejulianna(?![a-z])', 'niece julianna', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])mmmyeah(?![a-z])', 'yeah', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])eberybody(?![a-z])', 'everybody', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])pealedthe(?![a-z])', 'pealed the', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])summerrrrrrrrrr(?![a-z])', 'summer', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])torontolong(?![a-z])', 'toronto long', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])iiiit(?![a-z])', 'it', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])scaregood(?![a-z])', 'scsre good', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])blooowwws(?![a-z])', 'blows', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])sittingin(?![a-z])', 'sitting', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])hopingforrain(?![a-z])', 'hoping for rain', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])tonightahhhhhhhhhh(?![a-z])', 'tonight', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])vanillasky(?![a-z])', 'vanilla sky', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])thoroughgood(?![a-z])', 'thorough good', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])hopr(?![a-z])', 'hope', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])yupppppppp(?![a-z])', 'yup', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])inconsitent(?![a-z])', 'inconsistent', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])promfuck(?![a-z])', 'prom fuck', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])pigout(?![a-z])', 'pig out', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])mombrag(?![a-z])', 'mom brag', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])nevveerr(?![a-z])', 'never', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])wasfound(?![a-z])', 'was found', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])increasy(?![a-z])', 'increase', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])buzzzzzzz(?![a-z])', 'buzz', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])laptopiphone(?![a-z])', 'laptop mobile phone', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])luvfinally(?![a-z])', 'love finally', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])yeahhbaby(?![a-z])', 'yeah baby', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])cuz(?![a-z])', 'because', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])sayin(?![a-z])', 'saying', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])nuggetssss(?![a-z])', 'nuggets', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])csfullerton(?![a-z])', 'california state fullerton', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])obamapelosi(?![a-z])', 'obama pelosi', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])obamabidenpelosi(?![a-z])', 'obama biden pelosi', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])vp(?![a-z])', 'vice president', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])atoday(?![a-z])', 'a today', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])irancraziness(?![a-z])', 'iran craziness', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])fcking(?![a-z])', 'fucking', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])furkin(?![a-z])', 'fucking', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])contactsdoes(?![a-z])', 'contacts does', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])zomg(?![a-z])', 'oh my god', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])yearsgreat(?![a-z])', 'years great', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])funfun(?![a-z])', 'fun fun', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])fuin(?![a-z])', 'fun', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])superslow(?![a-z])', 'super slow', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])newswow(?![a-z])', 'news wow', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])baseballamericacom(?![a-z])', 'baseball america', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])phoneughh(?![a-z])', 'phone ugh', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])tonite(?![a-z])', 'tonight', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])scarey(?![a-z])', 'scary', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])propre(?![a-z])', 'proper', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])voiceover(?![a-z])', 'voice over', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])recentlyreleased(?![a-z])', 'recently released', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])supermarketing(?![a-z])', 'super marketing', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])byalex(?![a-z])', 'by alex', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])tv(?![a-z])', 'television', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])atebits(?![a-z])', 'ate bits', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])soooooo(?![a-z])', 'so', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])timewarner(?![a-z])', 'time warner', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])espnjus(?![a-z])', 'espn just', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])daybankrupt(?![a-z])', 'day bankrupt', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])dood(?![a-z])', 'dude', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])webdesign(?![a-z])', 'web design', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])finewhat(?![a-z])', 'fine what', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])loooooooovvvvvveee(?![a-z])', 'love', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])yeahhhhhhhhh(?![a-z])', 'yeah', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])tommorow(?![a-z])', 'tomorrow', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])gokey(?![a-z])', 'go key', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])hilariouslaugh(?![a-z])', 'hilarious laugh', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])hq(?![a-z])', 'headquarter', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])wtf(?![a-z])', 'what the fuck', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])hd(?![a-z])', 'high definition', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])youverse(?![a-z])', 'you verse', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])announcment(?![a-z])', 'announcement', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])newedge(?![a-z])', 'new edge', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])fck(?![a-z])', 'fuck', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])ajaxjquery(?![a-z])', 'ajax jquery', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])eectations(?![a-z])', 'expectations', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])slowlythey(?![a-z])', 'slowly they', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])fricken(?![a-z])', 'fucking', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])chartvisualization(?![a-z])', 'chart visualization', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])lovin(?![a-z])', 'loving', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])wthi(?![a-z])', 'with', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])sittercity(?![a-z])', 'sitter city', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])universitys(?![a-z])', 'universities', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])viewunited(?![a-z])', 'view united', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])goddam(?![a-z])', 'god damn', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])watchin(?![a-z])', 'watching', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])oughta(?![a-z])', 'ought to', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])insightfilled(?![a-z])', 'insight filled', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])socialentrepreneurship(?![a-z])', 'social entrepreneurship', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])lawnmowing(?![a-z])', 'lawn mowing', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])assesment(?![a-z])', 'assessment', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])ummm(?![a-z])', 'um', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])ui(?![a-z])', 'user interface', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])nooooooo(?![a-z])', 'no', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])rantsandraves(?![a-z])', 'rants and raves', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])goooood(?![a-z])', 'good', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])fav(?![a-z])', 'favorite', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])wftb(?![a-z])', 'what the fuck', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])movieit(?![a-z])', 'movie it', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])disruptionfred(?![a-z])', 'disruption fred', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])sooo(?![a-z])', 'so', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])pretenious(?![a-z])', 'pretentious', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])flockofseagullsweregeopoliticallycorrect(?![a-z])', 'flock of seagulls were geopolitically correct', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])surgerywishing(?![a-z])', 'surgery wishing', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])goodby(?![a-z])', 'goodbye', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])mmmmmfamily(?![a-z])', 'family', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])loooong(?![a-z])', 'long', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])ahhgot(?![a-z])', 'ah got', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])enuf(?![a-z])', 'enough', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])bball(?![a-z])', 'basketball', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])audiobook(?![a-z])', 'audio book', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])hahaha(?![a-z])', 'laughing', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])discomort(?![a-z])', 'discomfort', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])soooo(?![a-z])', 'so', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])dentistwho(?![a-z])', 'dentist who', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])tattoooos(?![a-z])', 'tattoos', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])itwill(?![a-z])', 'it will', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])omgg(?![a-z])', 'oh my god', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])stormweight(?![a-z])', 'storm weight', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])bitin(?![a-z])', 'biting', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])monsta(?![a-z])', 'monster', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])studing(?![a-z])', 'studying', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])programme(?![a-z])', 'program', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])braindead(?![a-z])', 'brain dead', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])viralvideo(?![a-z])', 'viral video', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])resultsby(?![a-z])', 'results by', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])shoulda(?![a-z])', 'should have', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])baack(?![a-z])', 'back', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])todaybut(?![a-z])', 'today but', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace('quot', '', case=False)\n",
    "testing_text['text'] = testing_text['text'].str.replace(r'(?<![a-z])e(?![a-z])', 'quote', case=False)\n",
    "\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])shoulda(?![a-z])', 'should have', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])baack(?![a-z])', 'back', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])todaybut(?![a-z])', 'today but', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace('quot', '', case=False)\n",
    "training_text['text'] = training_text['text'].str.replace(r'(?<![a-z])e(?![a-z])', 'quote', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stops(data_str):\n",
    "    # expects a string\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    text = data_str.split()\n",
    "    for word in text:\n",
    "        if word not in stops:\n",
    "            # rebuild cleaned_str\n",
    "            if list_pos == 0:\n",
    "                cleaned_str = word\n",
    "            else:\n",
    "                cleaned_str = cleaned_str + ' ' + word\n",
    "            list_pos += 1\n",
    "    return cleaned_str\n",
    "\n",
    "#def tag_and_remove(data_str):\n",
    "#    cleaned_str = ' '\n",
    "#    # noun tags\n",
    "#    nn_tags = ['NN', 'NNP', 'NNP', 'NNPS', 'NNS']\n",
    "#    # adjectives\n",
    "#    jj_tags = ['JJ', 'JJR', 'JJS']\n",
    "#    # verbs\n",
    "#    vb_tags = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "#    #adverbs\n",
    "#    av_tags = ['RB','RBR','RBS']\n",
    "#    nltk_tags = nn_tags + jj_tags + vb_tags + av_tags\n",
    "#\n",
    "#    # break string into 'words'\n",
    "#    text = data_str.split()\n",
    "#\n",
    "#    # tag the text and keep only those with the right tags\n",
    "#    #tagged_text = pos_tag(text)\n",
    "#    tagged_text = tagger.tag(text)\n",
    "#    for tagged_word in tagged_text:\n",
    "#        if tagged_word[1] in nltk_tags:\n",
    "#           cleaned_str += tagged_word[0] + ' '\n",
    "#\n",
    "#   return cleaned_str\n",
    "\n",
    "def tag_and_remove(data_str):\n",
    "    cleaned_str = ' '\n",
    "    # noun tags\n",
    "    nn_tags = ['NN', 'NNP', 'NNP', 'NNPS', 'NNS']\n",
    "    # adjectives\n",
    "    jj_tags = ['JJ', 'JJR', 'JJS']\n",
    "    # verbs\n",
    "    vb_tags = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "    #adverbs\n",
    "    av_tags = ['RB','RBR','RBS']\n",
    "    nltk_tags = nn_tags + jj_tags + vb_tags + av_tags\n",
    "\n",
    "    # break string into 'words'\n",
    "    text = data_str.split()\n",
    "\n",
    "    # tag the text and keep only those with the right tags\n",
    "    #tagged_text = pos_tag(text)\n",
    "    tagged_text = tagger.tag(text)\n",
    "    for tagged_word in tagged_text:\n",
    "        if tagged_word[1] in nltk_tags:\n",
    "            cleaned_str += tagged_word[0] + ' '\n",
    "\n",
    "    return cleaned_str\n",
    "\n",
    "def lemmatize(data_str):\n",
    "    # expects a string\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    text = data_str.split()\n",
    "    #tagged_words = pos_tag(text)\n",
    "    tagged_words = tagger.tag(text)\n",
    "    for word in tagged_words:\n",
    "        if 'v' in word[1].lower():\n",
    "            lemma = lmtzr.lemmatize(word[0], pos='v')\n",
    "        elif 'r' in word[1].lower():\n",
    "            lemma = lmtzr.lemmatize(word[0], pos='r')\n",
    "        elif 'a' in word[1].lower():\n",
    "            lemma = lmtzr.lemmatize(word[0], pos='a')\n",
    "        else:\n",
    "            lemma = lmtzr.lemmatize(word[0], pos='n')\n",
    "        if list_pos == 0:\n",
    "            cleaned_str = lemma\n",
    "        else:\n",
    "            cleaned_str = cleaned_str + ' ' + lemma\n",
    "        list_pos += 1\n",
    "    return cleaned_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_text['stop_text'] = training_text['text'].apply(remove_stops)\n",
    "testing_text['stop_text'] = testing_text['text'].apply(remove_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger = PerceptronTagger()\n",
    "training_text['tag_text'] = training_text['stop_text'].apply(tag_and_remove)\n",
    "testing_text['tag_text'] = testing_text['stop_text'].apply(tag_and_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_text['lemm_text'] = training_text['tag_text'].apply(lemmatize)\n",
    "testing_text['lemm_text'] = testing_text['tag_text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       awww bummer get david carr third day\n",
       "1          upset update facebook texting cry result schoo...\n",
       "2          dive many time ball manage save percent rest g...\n",
       "3                                 whole body feel itchy fire\n",
       "4                                             behave mad see\n",
       "5                                                 whole crew\n",
       "6                                                   need hug\n",
       "7          hey long time see yes rain bite bit laugh loud...\n",
       "8                                                       nope\n",
       "9                                                  que muera\n",
       "10                           spring break plain city snowing\n",
       "11                                             repierced ear\n",
       "12                     bear watch think ua loss embarrassing\n",
       "13                                count dont know never talk\n",
       "14                   first gun really zac snyder doucheclown\n",
       "15                              wish get watch miss premiere\n",
       "16         hollis death scene hurt severely watch film wr...\n",
       "17                                                  file tax\n",
       "18              ahh ive always want see rent love soundtrack\n",
       "19                       dear drinking forgotten table drink\n",
       "20                                           day get much do\n",
       "21           friend call ask meet mid valley today time sigh\n",
       "22                                           baked cake ated\n",
       "23                                               week go hop\n",
       "24                                      blagh class tomorrow\n",
       "25                                     hate call wake people\n",
       "26                              go cry sleep watching marley\n",
       "27                                          im sad misslilly\n",
       "28                 ooooh laugh loud leslie ok leslie get mad\n",
       "29         meh almost lover exception track get depressed...\n",
       "                                 ...                        \n",
       "1599970                                   thanks thanks look\n",
       "1599971                  thanks martin imaginative interface\n",
       "1599972                                 congrats mike way go\n",
       "1599973                         god office space wanna steal\n",
       "1599974    ahaha away everyone else see kara die yes aree...\n",
       "1599975    hey back thanks much kind note go make smile t...\n",
       "1599976                           yeah conscience clear case\n",
       "1599977                               thats girl dish advice\n",
       "1599978                                               second\n",
       "1599979                                               garden\n",
       "1599980                  jo jen nemuselo zrovna holce co nic\n",
       "1599981                                  comment contest yay\n",
       "1599982    figure see tweet facebook status update set gr...\n",
       "1599983    theri tomorrow drink coffee talk important fav...\n",
       "1599984      heard first girl hope look wendy brain kid babe\n",
       "1599985    lead singer band beware fall prey lsd lead sin...\n",
       "1599986                                         much ad blog\n",
       "1599987                                neveer think get well\n",
       "1599988    ha good job right gotta throw tag everywhere w...\n",
       "1599989                                         im glad well\n",
       "1599990                                          wooooo back\n",
       "1599991    mmmm sound absolutely perfect schedule full ti...\n",
       "1599992                                 recover long weekend\n",
       "1599993                                                     \n",
       "1599994    yeah work well wait end wonder time keep good ...\n",
       "1599995                        woke school best feeling ever\n",
       "1599996               thewdbcom cool hear old walt interview\n",
       "1599997                       ready mojo makeover ask detail\n",
       "1599998       happy th birthday alll time tupac amaru shakur\n",
       "1599999                                                happy\n",
       "Name: lemm_text, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_text['lemm_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       awww bummer got david carr third day\n",
       "1          upset update facebook texting might cry result...\n",
       "2          dived many times ball managed save percent res...\n",
       "3                           whole body feels itchy like fire\n",
       "4                                           behaving mad see\n",
       "5                                                 whole crew\n",
       "6                                                   need hug\n",
       "7          hey long time see yes rains bit bit laugh loud...\n",
       "8                                                       nope\n",
       "9                                                  que muera\n",
       "10                           spring break plain city snowing\n",
       "11                                            repierced ears\n",
       "12             could bear watch thought ua loss embarrassing\n",
       "13                counts dont know either never talk anymore\n",
       "14         would first gun really though zac snyder douch...\n",
       "15                              wish got watch miss premiere\n",
       "16         hollis death scene hurt severely watch film wr...\n",
       "17                                                file taxes\n",
       "18            ahh ive always wanted see rent love soundtrack\n",
       "19                   oh dear drinking forgotten table drinks\n",
       "20                                         day get much done\n",
       "21         one friend called asked meet mid valley today ...\n",
       "22                                           baked cake ated\n",
       "23                                          week going hoped\n",
       "24                                      blagh class tomorrow\n",
       "25                                     hate call wake people\n",
       "26                           going cry sleep watching marley\n",
       "27                                          im sad misslilly\n",
       "28                 ooooh laugh loud leslie ok leslie get mad\n",
       "29         meh almost lover exception track gets depresse...\n",
       "                                 ...                        \n",
       "1599970                                thanks thanks looking\n",
       "1599971                  thanks martin imaginative interface\n",
       "1599972                                 congrats mike way go\n",
       "1599973                      oh god office space wanna steal\n",
       "1599974    ahaha nooo away everyone else see kara would d...\n",
       "1599975    hey back thanks much kind notes gone made smil...\n",
       "1599976                     yeah conscience would clear case\n",
       "1599977                            thats girl dishing advice\n",
       "1599978                                               second\n",
       "1599979                                               garden\n",
       "1599980              jo jen nemuselo zrovna holce ael co nic\n",
       "1599981                       another commenting contest yay\n",
       "1599982    figured see tweets facebook status updates set...\n",
       "1599983    theri tomorrow drinking coffee talking importa...\n",
       "1599984    heard first girl hope looks wendy brains kiddi...\n",
       "1599985    lead singer band beware falling prey lsd lead ...\n",
       "1599986                                        much ads blog\n",
       "1599987                                neveer think get well\n",
       "1599988    ha good job right gotta throw tag everywhere w...\n",
       "1599989                                         im glad well\n",
       "1599990                                     wooooo xbox back\n",
       "1599991    mmmm sounds absolutely perfect schedule full t...\n",
       "1599992                              recovering long weekend\n",
       "1599993                                                     \n",
       "1599994    yeah work better waiting end wonder time keep ...\n",
       "1599995                        woke school best feeling ever\n",
       "1599996              thewdbcom cool hear old walt interviews\n",
       "1599997                      ready mojo makeover ask details\n",
       "1599998    happy th birthday boo alll time tupac amaru sh...\n",
       "1599999                                                happy\n",
       "Name: stop_text, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_text['stop_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_text[['sentiment','stop_text']].to_csv('stop_training.csv')\n",
    "testing_text[['sentiment','stop_text']].to_csv('stop_testing.csv')\n",
    "\n",
    "training_text[['sentiment','lemm_text']].to_csv('lemm_training.csv')\n",
    "testing_text[['sentiment','lemm_text']].to_csv('lemm_testing.csv')\n",
    "\n",
    "training_text[['sentiment','text']].to_csv('nothing_training.csv')\n",
    "testing_text[['sentiment','text']].to_csv('nothing_testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>stop_text</th>\n",
       "      <th>tag_text</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>awww that is a bummer you should have got dav...</td>\n",
       "      <td>awww bummer got david carr third day</td>\n",
       "      <td>awww bummer got david carr third day</td>\n",
       "      <td>awww bummer get david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "      <td>upset update facebook texting might cry result...</td>\n",
       "      <td>upset update facebook texting cry result scho...</td>\n",
       "      <td>upset update facebook texting cry result schoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>dived many times ball managed save percent res...</td>\n",
       "      <td>dived many times ball managed save percent re...</td>\n",
       "      <td>dive many time ball manage save percent rest g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>whole body feels itchy fire</td>\n",
       "      <td>whole body feel itchy fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>no it is not behaving at all i am mad why am i...</td>\n",
       "      <td>behaving mad see</td>\n",
       "      <td>behaving mad see</td>\n",
       "      <td>behave mad see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0   awww that is a bummer you should have got dav...   \n",
       "1          0  is upset that he can not update his facebook b...   \n",
       "2          0  i dived many times for the ball managed to sav...   \n",
       "3          0     my whole body feels itchy and like its on fire   \n",
       "4          0  no it is not behaving at all i am mad why am i...   \n",
       "\n",
       "                                           stop_text  \\\n",
       "0               awww bummer got david carr third day   \n",
       "1  upset update facebook texting might cry result...   \n",
       "2  dived many times ball managed save percent res...   \n",
       "3                   whole body feels itchy like fire   \n",
       "4                                   behaving mad see   \n",
       "\n",
       "                                            tag_text  \\\n",
       "0              awww bummer got david carr third day    \n",
       "1   upset update facebook texting cry result scho...   \n",
       "2   dived many times ball managed save percent re...   \n",
       "3                       whole body feels itchy fire    \n",
       "4                                  behaving mad see    \n",
       "\n",
       "                                           lemm_text  \n",
       "0               awww bummer get david carr third day  \n",
       "1  upset update facebook texting cry result schoo...  \n",
       "2  dive many time ball manage save percent rest g...  \n",
       "3                         whole body feel itchy fire  \n",
       "4                                     behave mad see  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>stop_text</th>\n",
       "      <th>tag_text</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>i love my kindle not that the dx is cool but t...</td>\n",
       "      <td>love kindle dx cool fantastic right</td>\n",
       "      <td>love kindle dx cool fantastic right</td>\n",
       "      <td>love kindle dx cool fantastic right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>reading my kindle love it lee childs is good read</td>\n",
       "      <td>reading kindle love lee childs good read</td>\n",
       "      <td>reading kindle love lee childs good read</td>\n",
       "      <td>read kindle love lee child good read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ok first assessment of the it fucking rocks</td>\n",
       "      <td>ok first assessment fucking rocks</td>\n",
       "      <td>ok first assessment fucking rocks</td>\n",
       "      <td>ok first assessment fucking rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>you will love your kindle i have had mine for ...</td>\n",
       "      <td>love kindle mine months never looked back new ...</td>\n",
       "      <td>love kindle mine months never looked new big ...</td>\n",
       "      <td>love kindle mine month never look new big huge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>fair enough but i have the kindle and i think ...</td>\n",
       "      <td>fair enough kindle think perfect</td>\n",
       "      <td>fair enough kindle think perfect</td>\n",
       "      <td>fair enough kindle think perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>no it is too big i am quite happy with the kindle</td>\n",
       "      <td>big quite happy kindle</td>\n",
       "      <td>big quite happy kindle</td>\n",
       "      <td>big quite happy kindle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>fuck this economy i hate aig and their non loa...</td>\n",
       "      <td>fuck economy hate aig non loan given asses</td>\n",
       "      <td>fuck economy hate aig non loan given asses</td>\n",
       "      <td>fuck economy hate aig non loan give ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>jquery is my new best friend</td>\n",
       "      <td>jquery new best friend</td>\n",
       "      <td>jquery new best friend</td>\n",
       "      <td>jquery new best friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>loves twitter</td>\n",
       "      <td>loves twitter</td>\n",
       "      <td>loves twitter</td>\n",
       "      <td>love twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>how can you not love obama he makes jokes abou...</td>\n",
       "      <td>love obama makes jokes</td>\n",
       "      <td>love obama makes jokes</td>\n",
       "      <td>love obama make joke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>i firmly believe that obama pelosi have zero d...</td>\n",
       "      <td>firmly believe obama pelosi zero desire civil ...</td>\n",
       "      <td>firmly believe obama pelosi desire civil char...</td>\n",
       "      <td>firmly believe obama pelosi desire civil chara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>house correspondents dinner was last night who...</td>\n",
       "      <td>house correspondents dinner last night whoopi ...</td>\n",
       "      <td>house correspondents dinner last night whoopi...</td>\n",
       "      <td>house correspondent dinner last night whoopi b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>watching espn just seen this new nike commeric...</td>\n",
       "      <td>watching espn seen new nike commerical puppet ...</td>\n",
       "      <td>watching espn seen new nike commerical puppet...</td>\n",
       "      <td>watch espn see new nike commerical puppet lebr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>dear nike stop with the flywire that shit is a...</td>\n",
       "      <td>dear nike stop flywire shit waste science ugly...</td>\n",
       "      <td>dear stop flywire shit waste science ugly love</td>\n",
       "      <td>dear stop flywire shit waste science ugly love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>best athlete of our generation if not all time...</td>\n",
       "      <td>best athlete generation time basketball relate...</td>\n",
       "      <td>best athlete generation time basketball relat...</td>\n",
       "      <td>best athlete generation time basketball relate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>i was talking to this guy last night and he wa...</td>\n",
       "      <td>talking guy last night telling die hard spurs ...</td>\n",
       "      <td>talking guy last night telling die hard spurs...</td>\n",
       "      <td>talk guy last night tell die hard spur fan als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>i love lebron</td>\n",
       "      <td>love lebron</td>\n",
       "      <td>love lebron</td>\n",
       "      <td>love lebron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>lebron is a beast but i am still cheering  the...</td>\n",
       "      <td>lebron beast still cheering today learned end</td>\n",
       "      <td>lebron beast still cheering today learned end</td>\n",
       "      <td>lebron beast still cheer today learn end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>lebron is the boss</td>\n",
       "      <td>lebron boss</td>\n",
       "      <td>lebron boss</td>\n",
       "      <td>lebron bos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>lebron is a hometown hero to me laugh out loud...</td>\n",
       "      <td>lebron hometown hero laugh loud love lakers le...</td>\n",
       "      <td>lebron hometown hero loud love lakers let go ...</td>\n",
       "      <td>lebron hometown hero loud love lakers let go c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>lebron and zydrunas are such an awesome duo</td>\n",
       "      <td>lebron zydrunas awesome duo</td>\n",
       "      <td>lebron awesome duo</td>\n",
       "      <td>lebron awesome duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>lebron is a beast nobody in the nba comes even...</td>\n",
       "      <td>lebron beast nobody nba comes even close</td>\n",
       "      <td>lebron beast nobody nba comes even close</td>\n",
       "      <td>lebron beast nobody nba come even close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>downloading apps for my iphone so much fun  th...</td>\n",
       "      <td>downloading apps iphone much fun literally app...</td>\n",
       "      <td>downloading apps iphone much fun literally ap...</td>\n",
       "      <td>download apps iphone much fun literally app an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>good news just had a call from the visa office...</td>\n",
       "      <td>good news call visa office saying everything f...</td>\n",
       "      <td>good news call visa office saying everything ...</td>\n",
       "      <td>good news call visa office say everything fine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>awesome come back from via</td>\n",
       "      <td>awesome come back via</td>\n",
       "      <td>awesome come back</td>\n",
       "      <td>awesome come back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>in montreal for a long weekend of areare much ...</td>\n",
       "      <td>montreal long weekend areare much needed</td>\n",
       "      <td>montreal long weekend areare much needed</td>\n",
       "      <td>montreal long weekend areare much need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>booz allen hamilton has a bad ass homegrown so...</td>\n",
       "      <td>booz allen hamilton bad ass homegrown social c...</td>\n",
       "      <td>booz allen hamilton bad ass homegrown social ...</td>\n",
       "      <td>booz allen hamilton bad as homegrown social co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>customer innovation award winner booz allen h...</td>\n",
       "      <td>customer innovation award winner booz allen ha...</td>\n",
       "      <td>customer innovation award winner booz hamilton</td>\n",
       "      <td>customer innovation award winner booz hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>i current use the nikon d and love it but not ...</td>\n",
       "      <td>current use nikon love much canon dd chose vid...</td>\n",
       "      <td>current use nikon love much canon dd chose vi...</td>\n",
       "      <td>current use nikon love much canon dd choose vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>google is always a good place to look should h...</td>\n",
       "      <td>google always good place look mentioned worked...</td>\n",
       "      <td>google always good place look mentioned worke...</td>\n",
       "      <td>google always good place look mention work mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>north korea please cease this douchebaggery ch...</td>\n",
       "      <td>north korea please cease douchebaggery china e...</td>\n",
       "      <td>north korea please cease douchebaggery china ...</td>\n",
       "      <td>north korea please cease douchebaggery china e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>why the hell is pelosi in freakin china and on...</td>\n",
       "      <td>hell pelosi freakin china whose dime</td>\n",
       "      <td>hell pelosi freakin china dime</td>\n",
       "      <td>hell pelosi freakin china dime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>are you burning more cash  than chrysler and g...</td>\n",
       "      <td>burning cash chrysler gm stop financial tsunam...</td>\n",
       "      <td>burning cash chrysler gm stop financial tsuna...</td>\n",
       "      <td>burn cash chrysler gm stop financial tsunami b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>insects have infected my spinach plant</td>\n",
       "      <td>insects infected spinach plant</td>\n",
       "      <td>insects infected spinach plant</td>\n",
       "      <td>insect infect spinach plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>wish i could catch every mosquito in the world...</td>\n",
       "      <td>wish could catch every mosquito world n burn e...</td>\n",
       "      <td>wish catch mosquito world n burn em slowly bi...</td>\n",
       "      <td>wish catch mosquito world n burn em slowly bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>just got back from church and i totally hate i...</td>\n",
       "      <td>got back church totally hate insects</td>\n",
       "      <td>got back church totally hate insects</td>\n",
       "      <td>get back church totally hate insect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>just got mcdonalds god damn those eggs make me...</td>\n",
       "      <td>got mcdonalds god damn eggs make sick yeah lak...</td>\n",
       "      <td>got mcdonalds god damn eggs make sick yeah la...</td>\n",
       "      <td>get mcdonalds god damn egg make sick yeah lake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>oh my god i ohhdee want mcdonalds damn i wonde...</td>\n",
       "      <td>oh god ohhdee want mcdonalds damn wonder open ...</td>\n",
       "      <td>god ohhdee want mcdonalds damn wonder open la...</td>\n",
       "      <td>god ohhdee want mcdonalds damn wonder open lau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>history exam studying ugh</td>\n",
       "      <td>history exam studying ugh</td>\n",
       "      <td>history exam studying ugh</td>\n",
       "      <td>history exam study ugh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>i hate revision it is so boring i am totally u...</td>\n",
       "      <td>hate revision boring totally unprepared exam t...</td>\n",
       "      <td>hate revision boring totally unprepared exam ...</td>\n",
       "      <td>hate revision bore totally unprepared exam tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>higher physics exam tomorrow not lookin forwar...</td>\n",
       "      <td>higher physics exam tomorrow lookin forward much</td>\n",
       "      <td>higher physics exam tomorrow forward much</td>\n",
       "      <td>higher physic exam tomorrow forward much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>it is a bank holiday yet i am only out of work...</td>\n",
       "      <td>bank holiday yet work exam season sucks</td>\n",
       "      <td>bank holiday yet work exam season sucks</td>\n",
       "      <td>bank holiday yet work exam season suck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>cheney and bush are the real culprits</td>\n",
       "      <td>cheney bush real culprits</td>\n",
       "      <td>cheney bush real culprits</td>\n",
       "      <td>cheney bush real culprit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "      <td>lifes a bitch and so is dick cheney</td>\n",
       "      <td>lifes bitch dick cheney</td>\n",
       "      <td>lifes bitch dick cheney</td>\n",
       "      <td>life bitch dick cheney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>dick cheney is dishonest speech about torture ...</td>\n",
       "      <td>dick cheney dishonest speech torture terror ob...</td>\n",
       "      <td>dick cheney dishonest speech torture terror o...</td>\n",
       "      <td>dick cheney dishonest speech torture terror ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>the republican party is a bunch of antiabortio...</td>\n",
       "      <td>republican party bunch antiabortion zealots co...</td>\n",
       "      <td>republican party bunch antiabortion zealots d...</td>\n",
       "      <td>republican party bunch antiabortion zealot dra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "      <td>is twitter is connections api broken some twee...</td>\n",
       "      <td>twitter connections api broken tweets make twi...</td>\n",
       "      <td>twitter connections api broken tweets make tw...</td>\n",
       "      <td>twitter connection api broken tweet make twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>i srsly hate the stupid twitter api timeout th...</td>\n",
       "      <td>srsly hate stupid twitter api timeout thing an...</td>\n",
       "      <td>srsly hate stupid twitter api thing annoying</td>\n",
       "      <td>srsly hate stupid twitter api thing annoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>i really liked  is learning jquery book is wor...</td>\n",
       "      <td>really liked learning jquery book worth look</td>\n",
       "      <td>really liked learning jquery book worth look</td>\n",
       "      <td>really liked learn jquery book worth look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>very interesting ad from adobe by goodbye silv...</td>\n",
       "      <td>interesting ad adobe goodbye silverstein partn...</td>\n",
       "      <td>interesting ad adobe goodbye silverstein part...</td>\n",
       "      <td>interest ad adobe goodbye silverstein partner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>goodbye silverstein agency new site great</td>\n",
       "      <td>goodbye silverstein agency new site great</td>\n",
       "      <td>goodbye silverstein agency new site great</td>\n",
       "      <td>goodbye silverstein agency new site great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>goodbye silverstein is new site i enjoy it ni...</td>\n",
       "      <td>goodbye silverstein new site enjoy nice find</td>\n",
       "      <td>goodbye silverstein new site enjoy nice find</td>\n",
       "      <td>goodbye silverstein new site enjoy nice find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>the ever amazing psyop and goodbye silverstein...</td>\n",
       "      <td>ever amazing psyop goodbye silverstein partner...</td>\n",
       "      <td>ever amazing psyop goodbye silverstein partne...</td>\n",
       "      <td>ever amaze psyop goodbye silverstein partner h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>top ten most watched on viral video chart love...</td>\n",
       "      <td>top ten watched viral video chart love nike ca...</td>\n",
       "      <td>top ten watched viral video chart love campai...</td>\n",
       "      <td>top ten watch viral video chart love campaign ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "      <td>oh my god i have a g</td>\n",
       "      <td>oh god g</td>\n",
       "      <td>god g</td>\n",
       "      <td>god g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "      <td>ok so lots of buzz from io but how lucky are t...</td>\n",
       "      <td>ok lots buzz io lucky free g</td>\n",
       "      <td>ok lots buzz io lucky free g</td>\n",
       "      <td>ok lot buzz io lucky free g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "      <td>just got a free g android at google io</td>\n",
       "      <td>got free g android google io</td>\n",
       "      <td>got free g android google io</td>\n",
       "      <td>get free g android google io</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>guess i will be retiring my g and start using ...</td>\n",
       "      <td>guess retiring g start using developer g woot</td>\n",
       "      <td>guess retiring g start using developer g woot</td>\n",
       "      <td>guess retire g start use developer g woot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>i am happy for philip being at googleio today</td>\n",
       "      <td>happy philip googleio today</td>\n",
       "      <td>happy philip googleio today</td>\n",
       "      <td>happy philip googleio today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1</td>\n",
       "      <td>lakers played great cannot wait for thursday n...</td>\n",
       "      <td>lakers played great cannot wait thursday night...</td>\n",
       "      <td>lakers played great cannot wait thursday nigh...</td>\n",
       "      <td>lakers play great cannot wait thursday night l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                                               text  \\\n",
       "0            1  i love my kindle not that the dx is cool but t...   \n",
       "1            1  reading my kindle love it lee childs is good read   \n",
       "2            1        ok first assessment of the it fucking rocks   \n",
       "3            1  you will love your kindle i have had mine for ...   \n",
       "4            1  fair enough but i have the kindle and i think ...   \n",
       "5            1  no it is too big i am quite happy with the kindle   \n",
       "6            0  fuck this economy i hate aig and their non loa...   \n",
       "7            1                       jquery is my new best friend   \n",
       "8            1                                      loves twitter   \n",
       "9            1  how can you not love obama he makes jokes abou...   \n",
       "11           0  i firmly believe that obama pelosi have zero d...   \n",
       "12           1  house correspondents dinner was last night who...   \n",
       "13           1  watching espn just seen this new nike commeric...   \n",
       "14           0  dear nike stop with the flywire that shit is a...   \n",
       "15           1  best athlete of our generation if not all time...   \n",
       "16           0  i was talking to this guy last night and he wa...   \n",
       "17           1                                      i love lebron   \n",
       "18           0  lebron is a beast but i am still cheering  the...   \n",
       "19           1                                 lebron is the boss   \n",
       "20           1  lebron is a hometown hero to me laugh out loud...   \n",
       "21           1        lebron and zydrunas are such an awesome duo   \n",
       "22           1  lebron is a beast nobody in the nba comes even...   \n",
       "23           1  downloading apps for my iphone so much fun  th...   \n",
       "24           1  good news just had a call from the visa office...   \n",
       "25           1                        awesome come back from via    \n",
       "26           1  in montreal for a long weekend of areare much ...   \n",
       "27           1  booz allen hamilton has a bad ass homegrown so...   \n",
       "28           1   customer innovation award winner booz allen h...   \n",
       "29           1  i current use the nikon d and love it but not ...   \n",
       "32           1  google is always a good place to look should h...   \n",
       "..         ...                                                ...   \n",
       "88           0  north korea please cease this douchebaggery ch...   \n",
       "89           0  why the hell is pelosi in freakin china and on...   \n",
       "90           0  are you burning more cash  than chrysler and g...   \n",
       "91           0            insects have infected my spinach plant    \n",
       "92           0  wish i could catch every mosquito in the world...   \n",
       "93           0  just got back from church and i totally hate i...   \n",
       "94           0  just got mcdonalds god damn those eggs make me...   \n",
       "95           1  oh my god i ohhdee want mcdonalds damn i wonde...   \n",
       "96           0                          history exam studying ugh   \n",
       "97           0  i hate revision it is so boring i am totally u...   \n",
       "98           0  higher physics exam tomorrow not lookin forwar...   \n",
       "99           0  it is a bank holiday yet i am only out of work...   \n",
       "100          0             cheney and bush are the real culprits    \n",
       "101          0                lifes a bitch and so is dick cheney   \n",
       "102          0  dick cheney is dishonest speech about torture ...   \n",
       "103          0  the republican party is a bunch of antiabortio...   \n",
       "104          0  is twitter is connections api broken some twee...   \n",
       "105          0  i srsly hate the stupid twitter api timeout th...   \n",
       "106          1  i really liked  is learning jquery book is wor...   \n",
       "108          1  very interesting ad from adobe by goodbye silv...   \n",
       "109          1          goodbye silverstein agency new site great   \n",
       "110          1   goodbye silverstein is new site i enjoy it ni...   \n",
       "111          1  the ever amazing psyop and goodbye silverstein...   \n",
       "112          1  top ten most watched on viral video chart love...   \n",
       "113          1                               oh my god i have a g   \n",
       "114          1  ok so lots of buzz from io but how lucky are t...   \n",
       "115          1             just got a free g android at google io   \n",
       "116          1  guess i will be retiring my g and start using ...   \n",
       "118          1      i am happy for philip being at googleio today   \n",
       "119          1  lakers played great cannot wait for thursday n...   \n",
       "\n",
       "                                             stop_text  \\\n",
       "0                  love kindle dx cool fantastic right   \n",
       "1             reading kindle love lee childs good read   \n",
       "2                    ok first assessment fucking rocks   \n",
       "3    love kindle mine months never looked back new ...   \n",
       "4                     fair enough kindle think perfect   \n",
       "5                               big quite happy kindle   \n",
       "6           fuck economy hate aig non loan given asses   \n",
       "7                               jquery new best friend   \n",
       "8                                        loves twitter   \n",
       "9                               love obama makes jokes   \n",
       "11   firmly believe obama pelosi zero desire civil ...   \n",
       "12   house correspondents dinner last night whoopi ...   \n",
       "13   watching espn seen new nike commerical puppet ...   \n",
       "14   dear nike stop flywire shit waste science ugly...   \n",
       "15   best athlete generation time basketball relate...   \n",
       "16   talking guy last night telling die hard spurs ...   \n",
       "17                                         love lebron   \n",
       "18       lebron beast still cheering today learned end   \n",
       "19                                         lebron boss   \n",
       "20   lebron hometown hero laugh loud love lakers le...   \n",
       "21                         lebron zydrunas awesome duo   \n",
       "22            lebron beast nobody nba comes even close   \n",
       "23   downloading apps iphone much fun literally app...   \n",
       "24   good news call visa office saying everything f...   \n",
       "25                               awesome come back via   \n",
       "26            montreal long weekend areare much needed   \n",
       "27   booz allen hamilton bad ass homegrown social c...   \n",
       "28   customer innovation award winner booz allen ha...   \n",
       "29   current use nikon love much canon dd chose vid...   \n",
       "32   google always good place look mentioned worked...   \n",
       "..                                                 ...   \n",
       "88   north korea please cease douchebaggery china e...   \n",
       "89                hell pelosi freakin china whose dime   \n",
       "90   burning cash chrysler gm stop financial tsunam...   \n",
       "91                      insects infected spinach plant   \n",
       "92   wish could catch every mosquito world n burn e...   \n",
       "93                got back church totally hate insects   \n",
       "94   got mcdonalds god damn eggs make sick yeah lak...   \n",
       "95   oh god ohhdee want mcdonalds damn wonder open ...   \n",
       "96                           history exam studying ugh   \n",
       "97   hate revision boring totally unprepared exam t...   \n",
       "98    higher physics exam tomorrow lookin forward much   \n",
       "99             bank holiday yet work exam season sucks   \n",
       "100                          cheney bush real culprits   \n",
       "101                            lifes bitch dick cheney   \n",
       "102  dick cheney dishonest speech torture terror ob...   \n",
       "103  republican party bunch antiabortion zealots co...   \n",
       "104  twitter connections api broken tweets make twi...   \n",
       "105  srsly hate stupid twitter api timeout thing an...   \n",
       "106       really liked learning jquery book worth look   \n",
       "108  interesting ad adobe goodbye silverstein partn...   \n",
       "109          goodbye silverstein agency new site great   \n",
       "110       goodbye silverstein new site enjoy nice find   \n",
       "111  ever amazing psyop goodbye silverstein partner...   \n",
       "112  top ten watched viral video chart love nike ca...   \n",
       "113                                           oh god g   \n",
       "114                       ok lots buzz io lucky free g   \n",
       "115                       got free g android google io   \n",
       "116      guess retiring g start using developer g woot   \n",
       "118                        happy philip googleio today   \n",
       "119  lakers played great cannot wait thursday night...   \n",
       "\n",
       "                                              tag_text  \\\n",
       "0                 love kindle dx cool fantastic right    \n",
       "1            reading kindle love lee childs good read    \n",
       "2                   ok first assessment fucking rocks    \n",
       "3     love kindle mine months never looked new big ...   \n",
       "4                    fair enough kindle think perfect    \n",
       "5                              big quite happy kindle    \n",
       "6          fuck economy hate aig non loan given asses    \n",
       "7                              jquery new best friend    \n",
       "8                                       loves twitter    \n",
       "9                              love obama makes jokes    \n",
       "11    firmly believe obama pelosi desire civil char...   \n",
       "12    house correspondents dinner last night whoopi...   \n",
       "13    watching espn seen new nike commerical puppet...   \n",
       "14     dear stop flywire shit waste science ugly love    \n",
       "15    best athlete generation time basketball relat...   \n",
       "16    talking guy last night telling die hard spurs...   \n",
       "17                                        love lebron    \n",
       "18      lebron beast still cheering today learned end    \n",
       "19                                        lebron boss    \n",
       "20    lebron hometown hero loud love lakers let go ...   \n",
       "21                                 lebron awesome duo    \n",
       "22           lebron beast nobody nba comes even close    \n",
       "23    downloading apps iphone much fun literally ap...   \n",
       "24    good news call visa office saying everything ...   \n",
       "25                                  awesome come back    \n",
       "26           montreal long weekend areare much needed    \n",
       "27    booz allen hamilton bad ass homegrown social ...   \n",
       "28     customer innovation award winner booz hamilton    \n",
       "29    current use nikon love much canon dd chose vi...   \n",
       "32    google always good place look mentioned worke...   \n",
       "..                                                 ...   \n",
       "88    north korea please cease douchebaggery china ...   \n",
       "89                     hell pelosi freakin china dime    \n",
       "90    burning cash chrysler gm stop financial tsuna...   \n",
       "91                     insects infected spinach plant    \n",
       "92    wish catch mosquito world n burn em slowly bi...   \n",
       "93               got back church totally hate insects    \n",
       "94    got mcdonalds god damn eggs make sick yeah la...   \n",
       "95    god ohhdee want mcdonalds damn wonder open la...   \n",
       "96                          history exam studying ugh    \n",
       "97    hate revision boring totally unprepared exam ...   \n",
       "98          higher physics exam tomorrow forward much    \n",
       "99            bank holiday yet work exam season sucks    \n",
       "100                         cheney bush real culprits    \n",
       "101                           lifes bitch dick cheney    \n",
       "102   dick cheney dishonest speech torture terror o...   \n",
       "103   republican party bunch antiabortion zealots d...   \n",
       "104   twitter connections api broken tweets make tw...   \n",
       "105      srsly hate stupid twitter api thing annoying    \n",
       "106      really liked learning jquery book worth look    \n",
       "108   interesting ad adobe goodbye silverstein part...   \n",
       "109         goodbye silverstein agency new site great    \n",
       "110      goodbye silverstein new site enjoy nice find    \n",
       "111   ever amazing psyop goodbye silverstein partne...   \n",
       "112   top ten watched viral video chart love campai...   \n",
       "113                                             god g    \n",
       "114                      ok lots buzz io lucky free g    \n",
       "115                      got free g android google io    \n",
       "116     guess retiring g start using developer g woot    \n",
       "118                       happy philip googleio today    \n",
       "119   lakers played great cannot wait thursday nigh...   \n",
       "\n",
       "                                             lemm_text  \n",
       "0                  love kindle dx cool fantastic right  \n",
       "1                 read kindle love lee child good read  \n",
       "2                     ok first assessment fucking rock  \n",
       "3    love kindle mine month never look new big huge...  \n",
       "4                     fair enough kindle think perfect  \n",
       "5                               big quite happy kindle  \n",
       "6              fuck economy hate aig non loan give ass  \n",
       "7                               jquery new best friend  \n",
       "8                                         love twitter  \n",
       "9                                 love obama make joke  \n",
       "11   firmly believe obama pelosi desire civil chara...  \n",
       "12   house correspondent dinner last night whoopi b...  \n",
       "13   watch espn see new nike commerical puppet lebr...  \n",
       "14      dear stop flywire shit waste science ugly love  \n",
       "15   best athlete generation time basketball relate...  \n",
       "16   talk guy last night tell die hard spur fan als...  \n",
       "17                                         love lebron  \n",
       "18            lebron beast still cheer today learn end  \n",
       "19                                          lebron bos  \n",
       "20   lebron hometown hero loud love lakers let go c...  \n",
       "21                                  lebron awesome duo  \n",
       "22             lebron beast nobody nba come even close  \n",
       "23   download apps iphone much fun literally app an...  \n",
       "24   good news call visa office say everything fine...  \n",
       "25                                   awesome come back  \n",
       "26              montreal long weekend areare much need  \n",
       "27   booz allen hamilton bad as homegrown social co...  \n",
       "28      customer innovation award winner booz hamilton  \n",
       "29   current use nikon love much canon dd choose vi...  \n",
       "32   google always good place look mention work mus...  \n",
       "..                                                 ...  \n",
       "88   north korea please cease douchebaggery china e...  \n",
       "89                      hell pelosi freakin china dime  \n",
       "90   burn cash chrysler gm stop financial tsunami b...  \n",
       "91                         insect infect spinach plant  \n",
       "92   wish catch mosquito world n burn em slowly bit...  \n",
       "93                 get back church totally hate insect  \n",
       "94   get mcdonalds god damn egg make sick yeah lake...  \n",
       "95   god ohhdee want mcdonalds damn wonder open lau...  \n",
       "96                              history exam study ugh  \n",
       "97   hate revision bore totally unprepared exam tom...  \n",
       "98            higher physic exam tomorrow forward much  \n",
       "99              bank holiday yet work exam season suck  \n",
       "100                           cheney bush real culprit  \n",
       "101                             life bitch dick cheney  \n",
       "102  dick cheney dishonest speech torture terror ob...  \n",
       "103  republican party bunch antiabortion zealot dra...  \n",
       "104   twitter connection api broken tweet make twitter  \n",
       "105          srsly hate stupid twitter api thing annoy  \n",
       "106          really liked learn jquery book worth look  \n",
       "108  interest ad adobe goodbye silverstein partner ...  \n",
       "109          goodbye silverstein agency new site great  \n",
       "110       goodbye silverstein new site enjoy nice find  \n",
       "111  ever amaze psyop goodbye silverstein partner h...  \n",
       "112  top ten watch viral video chart love campaign ...  \n",
       "113                                              god g  \n",
       "114                        ok lot buzz io lucky free g  \n",
       "115                       get free g android google io  \n",
       "116          guess retire g start use developer g woot  \n",
       "118                        happy philip googleio today  \n",
       "119  lakers play great cannot wait thursday night l...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_text.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
