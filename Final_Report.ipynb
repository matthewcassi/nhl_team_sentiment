{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy as sp\n",
    "\n",
    "scores = pd.read_csv('final_scores.csv')\n",
    "scores.drop('Unnamed: 0', 1, inplace=True)\n",
    "lr_stop_tfidf_vec_ngrams_limited = joblib.load('/Users/matthewcassi/Documents/nhl_sentiment_working/no_num_hash_mentions/predictions/log_reg/lr_stop_tfidf_vec_ngrams.pkl')\n",
    "data = pd.read_csv('/Users/matthewcassi/Documents/nhl_sentiment_working/sentiment_data/none/stop_training.csv')\n",
    "data.drop('Unnamed: 0', 1, inplace=True)\n",
    "data = data.dropna()\n",
    "\n",
    "data_y = data['sentiment']\n",
    "data_x = data['stop_text']\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=20, max_df=.9, ngram_range=(1,3))\n",
    "vectorizer.fit_transform(data_x)\n",
    "\n",
    "words = np.array(vectorizer.get_feature_names())\n",
    "x_test = pd.DataFrame(words, columns=['word']).reset_index()\n",
    "probs = lr_stop_tfidf_vec_ngrams_limited.predict_proba(x_test['word'])[:,1]\n",
    "ind = np.argsort(probs)\n",
    "\n",
    "good_words = words[ind[:15]]\n",
    "bad_words = words[ind[-15:]]\n",
    "\n",
    "good_prob = probs[ind[:15]]\n",
    "bad_prob = probs[ind[-15:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHL Rankings\n",
    "\n",
    "After running the team tweets through the final model, the ranking of the teams are shown in the table below.\n",
    "\n",
    "|Ranking| Team | Positivity Score|\n",
    "| --------- | ------------- |:-------------:|\n",
    "|1|![alt text](team_images/ducks.gif \"Anaheim Ducks\") | 0.707800 |\n",
    "|2|![alt text](team_images/kings.gif \"Los Angeles Kings\") | 0.700027 |\n",
    "|3|![alt text](team_images/preds.gif \"Nashville Predators\") | 0.694269 |\n",
    "|4|![alt text](team_images/wings.gif \"Detroit Red Wings\") | 0.692764 |\n",
    "|5|![alt text](team_images/avs.gif \"Colorado Avalanche\") | 0.691150 |\n",
    "|6|![alt text](team_images/yotes.gif \"Arizona Coyotes\") | 0.689593 |\n",
    "|7|![alt text](team_images/knights.gif \"Vegas Golden Knights\") | 0.688557 |\n",
    "|8|![alt text](team_images/pens.gif \"Pittsburgh Penguins\") | 0.685668 |\n",
    "|9|![alt text](team_images/canes.gif \"Carolina Hurricanes\") | 0.683068 |\n",
    "|10|![alt text](team_images/stars.gif \"Dallas Stars\") | 0.680438 |\n",
    "|11|![alt text](team_images/wild.gif \"Minnesota Wild\") | 0.673547 |\n",
    "|12|![alt text](team_images/flyers.gif \"Philadelphia Flyers\") | 0.668847 |\n",
    "|13|![alt text](team_images/jets.gif \"Winnipeg Jets\") | 0.666481 |\n",
    "|14|![alt text](team_images/jackets.gif \"Columbus Blue Jackets\") | 0.660425 |\n",
    "|15|![alt text](team_images/sharks.gif \"San Jose Sharks\") | 0.655994 |\n",
    "|16|![alt text](team_images/bolts.gif \"Tampa Bay Lightning\") | 0.650761 |\n",
    "|17|![alt text](team_images/bruins.gif \"Boston Bruins\") | 0.646160 |\n",
    "|18|![alt text](team_images/caps.gif \"Washington Capitals\") | 0.645995 |\n",
    "|19|![alt text](team_images/blues.gif \"St. Louis Blues\") | 0.618353 |\n",
    "|20|![alt text](team_images/leafs.gif \"Toronto Maple Leafs\") | 0.611547 |\n",
    "|21|![alt text](team_images/rangers.gif \"New York Rangers\") | 0.610007 |\n",
    "|22|![alt text](team_images/isles.gif \"New York Islanders\") | 0.608599 |\n",
    "|23|![alt text](team_images/canucks.gif \"Vancouver Canucks\") | 0.604013 |\n",
    "|24|![alt text](team_images/panthers.gif \"Florida Panthers\") | 0.600806 |\n",
    "|25|![alt text](team_images/sabres.gif \"Buffalo Sabres\") | 0.593559 |\n",
    "|26|![alt text](team_images/flames.gif \"Calgary Flames\") | 0.586288 |\n",
    "|27|![alt text](team_images/habs.gif \"Montreal Canadiens\") | 0.578462 |\n",
    "|28|![alt text](team_images/sens.gif \"Ottawa Senators\") | 0.570220 |\n",
    "|29|![alt text](team_images/hawks.gif \"Chicago Blackhawks\") | 0.568190 |\n",
    "|30|![alt text](team_images/oilers.gif \"Edmonton Oilers\") | 0.562418 |\n",
    "|31|![alt text](team_images/devils.gif \"New Jersey Devils\") | 0.557760 |\n",
    "\n",
    "\n",
    "It is surprising to see all teams having more positive tweets than negative tweets. However, the week that the tweets were collected was right before the All-Star break and every team sends one player to the game. I think tweets are a little more positive as every team's fans get to see something good happen, even if their season isn't going well. Also, I collected bloggers' tweets and based on the blogs that I've read, their tweets are generally more positive than regular fans that reply to team accounts.\n",
    "\n",
    "Despite the tweets being overly positive, the rankings do, for the most part, reflect how the season is going. The teams at the bottom were not playing well (Blackhawks, Oilers, Senators), while the teams at the top were playing well (Kings, Predators, Avalanche). \n",
    "\n",
    "## NHL Rankings Comparison\n",
    "The top three models were used to classify the team tweets. The chart below shows the different rankings.\n",
    "\n",
    "|Rank| Team | Positivity Score Final | | Team | Positivity Second Model | | Team | Positivity Third Model |\n",
    "|-------------| :-------------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|\n",
    "|1|![alt text](team_images/ducks.gif \"Anaheim Ducks\")|0.707800| |![alt text](team_images/ducks.gif \"Anaheim Ducks\")| 0.719829| |![alt text](team_images/ducks.gif \"Anaheim Ducks\")|0.670547|\n",
    "|2|![alt text](team_images/kings.gif \"Los Angeles Kings\")|0.700027| |![alt text](team_images/kings.gif \"Los Angeles Kings\")|0.701100| |![alt text](team_images/kings.gif \"Los Angeles Kings\")|0.653072|\n",
    "|3|![alt text](team_images/preds.gif \"Nashville Predators\")|0.694269| |![alt text](team_images/wings.gif \"Detroit Red Wings\")|0.699509| |![alt text](team_images/wings.gif \"Detroit Red Wings\")|0.652494|\n",
    "|4|![alt text](team_images/wings.gif \"Detroit Red Wings\")|0.692764| |![alt text](team_images/preds.gif \"Nashville Predators\")|0.697628| |![alt text](team_images/knights.gif \"Vegas Golden Knights\")|0.649031|\n",
    "|5|![alt text](team_images/avs.gif \"Colorado Avalanche\")| 0.691150 | |![alt text](team_images/avs.gif \"Colorado Avalanche\")|0.697170| |![alt text](team_images/canes.gif \"Carolina Hurricanes\")|0.641504|\n",
    "|6|![alt text](team_images/yotes.gif \"Arizona Coyotes\")|0.689593||![alt text](team_images/knights.gif \"Vegas Golden Knights\")|0.691941| |![alt text](team_images/pens.gif \"Pittsburgh Penguins\")|0.640676|\n",
    "|7|![alt text](team_images/knights.gif \"Vegas Golden Knights\")|0.688557| |![alt text](team_images/yotes.gif \"Arizona Coyotes\")|0.690950| |![alt text](team_images/avs.gif \"Colorado Avalanche\")|0.638772|\n",
    "|8|![alt text](team_images/pens.gif \"Pittsburgh Penguins\")|0.685668| |![alt text](team_images/pens.gif \"Pittsburgh Penguins\")|0.689943| |![alt text](team_images/stars.gif \"Dallas Stars\")|0.637880|\n",
    "|9|![alt text](team_images/canes.gif \"Carolina Hurricanes\")|0.683068| |![alt text](team_images/stars.gif \"Dallas Stars\")|0.687407| |![alt text](team_images/flyers.gif \"Philadelphia Flyers\")|0.626945|\n",
    "|10|![alt text](team_images/stars.gif \"Dallas Stars\")|0.680438| |![alt text](team_images/canes.gif \"Carolina Hurricanes\")|0.687347| |![alt text](team_images/yotes.gif \"Arizona Coyotes\")|0.622624|\n",
    "|11|![alt text](team_images/wild.gif \"Minnesota Wild\")|0.673547| |![alt text](team_images/wild.gif \"Minnesota Wild\")|0.676351| |![alt text](team_images/jackets.gif \"Columbus Blue Jackets\")|0.620871|\n",
    "|12|![alt text](team_images/flyers.gif \"Philadelphia Flyers\")|0.668847| |![alt text](team_images/flyers.gif \"Philadelphia Flyers\")|0.673444| |![alt text](team_images/wild.gif \"Minnesota Wild\")|0.619521|\n",
    "|13|![alt text](team_images/jets.gif \"Winnipeg Jets\")|0.666481| |![alt text](team_images/jets.gif \"Winnipeg Jets\")|0.670385| |![alt text](team_images/preds.gif \"Nashville Predators\")|0.611067|\n",
    "|14|![alt text](team_images/jackets.gif \"Columbus Blue Jackets\")|0.660425| |![alt text](team_images/jackets.gif \"Columbus Blue Jackets\")|0.663791| |![alt text](team_images/caps.gif \"Washington Capitals\")|0.607235|\n",
    "|15|![alt text](team_images/sharks.gif \"San Jose Sharks\")|0.655994| |![alt text](team_images/sharks.gif \"San Jose Sharks\")|0.660867| |![alt text](team_images/sharks.gif \"San Jose Sharks\")|0.606925|\n",
    "|16|![alt text](team_images/bolts.gif \"Tampa Bay Lightning\")|0.650761| |![alt text](team_images/bolts.gif \"Tampa Bay Lightning\")|0.650761| |![alt text](team_images/bolts.gif \"Tampa Bay Lightning\")|0.601785|\n",
    "|17|![alt text](team_images/bruins.gif \"Boston Bruins\")|0.646160| |![alt text](team_images/bruins.gif \"Boston Bruins\")|0.648605| |![alt text](team_images/bruins.gif \"Boston Bruins\")|0.580566|\n",
    "|18|![alt text](team_images/caps.gif \"Washington Capitals\")|0.645995| |![alt text](team_images/caps.gif \"Washington Capitals\")|0.648292| |![alt text](team_images/blues.gif \"St. Louis Blues\")|0.579117|\n",
    "|19|![alt text](team_images/blues.gif \"St. Louis Blues\")|0.618353| |![alt text](team_images/blues.gif \"St. Louis Blues\")|0.623070| |![alt text](team_images/rangers.gif \"New York Rangers\")|0.574480|\n",
    "|20|![alt text](team_images/leafs.gif \"Toronto Maple Leafs\")|0.611547| |![alt text](team_images/leafs.gif \"Toronto Maple Leafs\")|0.615678| |![alt text](team_images/isles.gif \"New York Islanders\")|0.574450|\n",
    "|21|![alt text](team_images/rangers.gif \"New York Rangers\")|0.610007| |![alt text](team_images/rangers.gif \"New York Rangers\")|0.613891| |![alt text](team_images/leafs.gif \"Toronto Maple Leafs\")|0.567691|\n",
    "|22|![alt text](team_images/isles.gif \"New York Islanders\")|0.608599| |![alt text](team_images/isles.gif \"New York Islanders\")|0.613162| |![alt text](team_images/canucks.gif \"Vancouver Canucks\")|0.567657|\n",
    "|23|![alt text](team_images/canucks.gif \"Vancouver Canucks\")|0.604013| |![alt text](team_images/canucks.gif \"Vancouver Canucks\")|0.611404| |![alt text](team_images/panthers.gif \"Florida Panthers\")|0.558468|\n",
    "|24|![alt text](team_images/panthers.gif \"Florida Panthers\")|0.600806| |![alt text](team_images/panthers.gif \"Florida Panthers\")|0.607863| |![alt text](team_images/sabres.gif \"Buffalo Sabres\")|0.555252|\n",
    "|25|![alt text](team_images/sabres.gif \"Buffalo Sabres\")|0.593559| |![alt text](team_images/sabres.gif \"Buffalo Sabres\")|0.597558| |![alt text](team_images/habs.gif \"Montreal Canadiens\")|0.555150|\n",
    "|26|![alt text](team_images/flames.gif \"Calgary Flames\")|0.586288| |![alt text](team_images/flames.gif \"Calgary Flames\")|0.585763| |![alt text](team_images/bolts.gif \"Tampa Bay Lightning\")|0.553976|\n",
    "|27|![alt text](team_images/habs.gif \"Montreal Canadiens\")|0.578462| |![alt text](team_images/habs.gif \"Montreal Canadiens\")|0.582985| |![alt text](team_images/flames.gif \"Calgary Flames\")|0.539795|\n",
    "|28|![alt text](team_images/sens.gif \"Ottawa Senators\")|0.570220| |![alt text](team_images/sens.gif \"Ottawa Senators\")|0.573461| |![alt text](team_images/sens.gif \"Ottawa Senators\")|0.527908|\n",
    "|29|![alt text](team_images/hawks.gif \"Chicago Blackhawks\")|0.568190| |![alt text](team_images/hawks.gif \"Chicago Blackhawks\")|0.570918| |![alt text](team_images/oilers.gif \"Edmonton Oilers\")|0.521430|\n",
    "|30|![alt text](team_images/oilers.gif \"Edmonton Oilers\")|0.562418| |![alt text](team_images/oilers.gif \"Edmonton Oilers\")|0.566910| |![alt text](team_images/hawks.gif \"Chicago Blackhawks\")|0.511663|\n",
    "|31|![alt text](team_images/devils.gif \"New Jersey Devils\")|0.557760| |![alt text](team_images/devils.gif \"New Jersey Devils\")|0.554229| |![alt text](team_images/devils.gif \"New Jersey Devils\")|0.508828|\n",
    "\n",
    "\n",
    "In the table below, you can see the average rankings between the top three models. The rankings for the teams are relatively the same with the Naive Bayes model being the most different. The two Logisitic Regression models performed almost the same, which was to be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>final_model_rank</th>\n",
       "      <th>second_model_rank</th>\n",
       "      <th>third_model_rank</th>\n",
       "      <th>average_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anaheim Ducks</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Los Angeles Kings</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detroit Red Wings</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colorado Avalanche</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vegas Golden Knights</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nashville Predators</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pittsburgh Penguins</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arizona Coyotes</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Carolina Hurricanes</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dallas Stars</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Philadelphia Flyers</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Minnesota Wild</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>11.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Columbus Blue Jackets</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Winnipeg Jets</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>San Jose Sharks</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Washington Capitals</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Boston Bruins</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>St. Louis Blues</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>18.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tampa Bay Lightning</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>19.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Toronto Maple Leafs</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>20.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>New York Rangers</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>20.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New York Islanders</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Vancouver Canucks</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>22.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Florida Panthers</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>23.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Buffalo Sabres</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>24.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>26.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Montreal Canadiens</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>26.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ottawa Senators</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Chicago Blackhawks</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Edmonton Oilers</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New Jersey Devils</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     team  final_model_rank  second_model_rank  \\\n",
       "0           Anaheim Ducks                 1                  1   \n",
       "1       Los Angeles Kings                 2                  2   \n",
       "3       Detroit Red Wings                 4                  3   \n",
       "4      Colorado Avalanche                 5                  5   \n",
       "6    Vegas Golden Knights                 7                  6   \n",
       "2     Nashville Predators                 3                  4   \n",
       "7     Pittsburgh Penguins                 8                  8   \n",
       "5         Arizona Coyotes                 6                  7   \n",
       "8     Carolina Hurricanes                 9                 10   \n",
       "9            Dallas Stars                10                  9   \n",
       "11    Philadelphia Flyers                12                 12   \n",
       "10         Minnesota Wild                11                 11   \n",
       "13  Columbus Blue Jackets                14                 14   \n",
       "12          Winnipeg Jets                13                 13   \n",
       "14        San Jose Sharks                15                 15   \n",
       "17    Washington Capitals                18                 18   \n",
       "16          Boston Bruins                17                 17   \n",
       "18        St. Louis Blues                19                 19   \n",
       "15    Tampa Bay Lightning                16                 16   \n",
       "19    Toronto Maple Leafs                20                 20   \n",
       "20       New York Rangers                21                 21   \n",
       "21     New York Islanders                22                 22   \n",
       "22      Vancouver Canucks                23                 23   \n",
       "23       Florida Panthers                24                 24   \n",
       "24         Buffalo Sabres                25                 25   \n",
       "25         Calgary Flames                26                 26   \n",
       "26     Montreal Canadiens                27                 27   \n",
       "27        Ottawa Senators                28                 28   \n",
       "28     Chicago Blackhawks                29                 29   \n",
       "29        Edmonton Oilers                30                 30   \n",
       "30      New Jersey Devils                31                 31   \n",
       "\n",
       "    third_model_rank  average_rank  \n",
       "0                  1      1.000000  \n",
       "1                  2      2.000000  \n",
       "3                  3      3.333333  \n",
       "4                  7      5.666667  \n",
       "6                  4      5.666667  \n",
       "2                 13      6.666667  \n",
       "7                  6      7.333333  \n",
       "5                 10      7.666667  \n",
       "8                  5      8.000000  \n",
       "9                  8      9.000000  \n",
       "11                 9     11.000000  \n",
       "10                12     11.333333  \n",
       "13                11     13.000000  \n",
       "12                16     14.000000  \n",
       "14                15     15.000000  \n",
       "17                14     16.666667  \n",
       "16                17     17.000000  \n",
       "18                18     18.666667  \n",
       "15                26     19.333333  \n",
       "19                21     20.333333  \n",
       "20                19     20.333333  \n",
       "21                20     21.333333  \n",
       "22                22     22.666667  \n",
       "23                23     23.666667  \n",
       "24                24     24.666667  \n",
       "25                27     26.333333  \n",
       "26                25     26.333333  \n",
       "27                28     28.000000  \n",
       "28                30     29.333333  \n",
       "29                29     29.666667  \n",
       "30                31     31.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hockey_rankings = pd.read_csv('rankings.csv')\n",
    "hockey_rankings.sort_values('average_rank', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidePrompt": true
   },
   "source": [
    "# I. Project Description\n",
    "The NHL Sentiment Analysis ranked NHL teams according to the positivity of tweets directed at each team account, tweets from team bloggers, and tweets with team hashtags (like #nyr for the New York Rangers). To rank the tweets, a sentiment algorithm had to be created with tweets that were already classified as positive or negative. [Sentiment140](http://help.sentiment140.com/for-students) has a set of a training set consisting of 1.6 million tweets that are already classified with a test set that has been classified too. These tweets were used to build the algorithm used to rank the NHL teams.\n",
    "\n",
    "# II. Data Gathering\n",
    "Using the Tweepy package for Python, I was able to stream tweets from each team, bloggers, and tweets using team hashtags. I streamed tweets from January 20th through January 25th, which was the start of the All Star break. I collected around 2 GB of tweets (450k), which after cleaning was reduced to 160k, due to duplicates and tweets that were picked up due to hashtags like #stars (Dallas Stars) and #wild (Minnesota Wild).\n",
    "\n",
    "# III. Data Cleaning\n",
    "\n",
    "   ## A. Parsing NHL Tweets\n",
    "The tweet data came in JSON format but was a challenge to handle. Each possible JSON field was not included for each tweet (extra fields for retweets and quoted tweets) if they were not present in the tweet. The data were loaded into Python using Pandas and some of the columns contained embedded JSON, like mentions, hashtags, and twitter users included in the tweets. These columns were parsed and turned into lists so that they could be used to determine what teams were included in the tweets. Using the hashtags and accounts that were followed, I was able to look at the lists of mentions, users, and hashtags to determine the teams in the tweets. After completing this, each tweet contained a list of teams included in the tweet (for example, there were tweets with 2 teams [nyr, canes] for the New York Rangers and the Carolina Hurricanes)\n",
    "\n",
    "There were also multiple columns included in the dataset for the actual tweets. There were 140 and 280 character tweet fields for plain tweets, for retweets, for quoted tweets, and retweeted quoted tweets. If a tweet was longer than 140 characters then it was cut off in the 140 field. If the tweet was less than 140 characters, then the 280 character field was blank. Using that logic, I was able to reduce the 8 columns to 4: one for tweets, one for retweets, one for quoted tweets, and one for retweeted quoted tweets. \n",
    "\n",
    "After further inspection of the tweets, quoted tweets and regular tweets ended up being the same thing in certain cases. The same could be said for the retweets and retweeted quoted tweets. Using those two facts, I was able to reduce the number of columns to 2 text columns: one for tweets and quotes and another for retweets and retweeted quoted tweets. Because I had a list of teams per tweet, I was able to concatenate the retweets with the regular tweets with the retweets to form one list of tweets with teams associated to each.\n",
    "\n",
    "   ## B. Cleaning NHL Tweets\n",
    "The NHL tweets contained punctuation, numbers, capital letters, misspellings, URLs, mentions (@usernames), and emojis. The first thing to do was to change all of the text to lowercase and then remove numbers, hashtags, URLs, mentions, and emojis. This was done so that only relevant text was used to determine if a tweet was positive or negative. \n",
    "\n",
    "The next step in the cleaning involved changing popular social media acronyms to actual words (for example, lol is laugh out loud). The next step was to correct some of the spelling errors. Using NLTK and big text, I was able to compare the words used in NLTK’s datasets and produce a list of words that were misspelled. I corrected about 150 unique spelling mistakes in each tweet, which left around 29k unique spelling errors. The rest were left as there were too many words to correct. \n",
    "\n",
    "The final two steps involved removing stopwords and lemmatizing words using NLTK. Stopwords are words that do not add value to a sentence like the, a, and how. Lemmatizing words is the process of returning words to their base dictionary form. For example, if you lemmatize the word goals, it becomes goal. This is important when it comes to building an algorithm. If you count the words that are used in tweets, goals and goal would end up as two separate counts, Lemmatizing goals allows you to combine the two together as they become the same word (goal).\n",
    "\n",
    "   ## C. Sentiment140 Data\n",
    "The same process that was used to clean the NHL tweets was used to clean the Sentiment140 tweets. The text was changed to all lowercase and then punctuation, URLs, mentions, hashtags, emojis, and numbers were removed. The tweets were then checked for spelling errors. These tweets contained 300k unique spelling errors and only ~150 unique changes were made. The final step was to remove stopwords and then lemmatize the words.\n",
    "\n",
    "# IV. Modeling\n",
    "   ## A. Model Evaluation\n",
    "There were multiple metrics used to determine which model performed best on the training data, test data, and validation dataset. The first metric is accuracy which is the number of correct guesses divided by the number of total guesses (true positives + true negatives / (true positives + true negatives + false positives + false negatives). The second metric was precision which is the . Recall is the third metric which is the . The final metric is the area under the curve (AUC) of the receiver operating characteristic (ROC) curve. The AUC measures the probability “that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one” according to Tom Fawcett’s “An introduction to ROC analysis.” In all 4 metrics, the metrics are between 0 and 1, with 1 being the best possible value.\n",
    "\n",
    "These metrics were calculated on using the models on a training set, a testing set, and a validation set. The model that had the best combination of all of the metrics was selected to rank the NHL team tweets.\n",
    "\n",
    "   ## B. Building Models\n",
    "All of the models used in this analysis were built with two different text sets: text with stop words removed and text with stopwords removed and lemmatized words. The Sentiment140 training set was split into a training set and testing set (95% training and 5% testing). \n",
    "\n",
    "The models used to included Naive Bayes Classifiers, Logistic Regression Classifiers, Support Vector Machine Classifiers, and Random Forest Classifiers. In addition to these models, different vectorization (creating a matrix of every word included in the tweets and counting words) techniques were used to plug the text data into the different models. A simple count vectorization was used for the models as well as a TFIDF vectorizer. TFIDF is a way to show which words are most important in a text by counting the number of times a word appears in a tweet and then dividing that by how common or rare the word is. If a word is more popular like ‘the’, the the TFIDF of the word would be low because it is common.\n",
    "\n",
    "These models and vectorizers have multiple parameters to vary like the the cap for TFIDF values (the highest value a word could have like .8 or .9), the depth of Random Forest Trees, and the penalty (L1 vs. L2) for Logistic Regression. These parameters were varied using Cross Validation with 3 folds. This was done to get the best performing model based on the different parameter values. \n",
    "\n",
    "At the end of the process, all of the models were combined to show all of their different metrics in one chart (shown below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>roc_test</th>\n",
       "      <th>fn_test</th>\n",
       "      <th>fp_test</th>\n",
       "      <th>accuracy_val</th>\n",
       "      <th>precision_val</th>\n",
       "      <th>recall_val</th>\n",
       "      <th>roc_val</th>\n",
       "      <th>fn_val</th>\n",
       "      <th>fp_val</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression Stop TFIDF Ngrams</td>\n",
       "      <td>0.808545</td>\n",
       "      <td>0.785264</td>\n",
       "      <td>0.777469</td>\n",
       "      <td>0.800487</td>\n",
       "      <td>0.785234</td>\n",
       "      <td>7952</td>\n",
       "      <td>9132</td>\n",
       "      <td>0.832869</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.832914</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic Regression Stop TFIDF Ngrams Limited</td>\n",
       "      <td>0.806642</td>\n",
       "      <td>0.788695</td>\n",
       "      <td>0.780734</td>\n",
       "      <td>0.804024</td>\n",
       "      <td>0.788665</td>\n",
       "      <td>7811</td>\n",
       "      <td>9000</td>\n",
       "      <td>0.824513</td>\n",
       "      <td>0.828729</td>\n",
       "      <td>0.824176</td>\n",
       "      <td>0.824517</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes Stop TFIDF Ngrams</td>\n",
       "      <td>0.783524</td>\n",
       "      <td>0.772053</td>\n",
       "      <td>0.772780</td>\n",
       "      <td>0.771985</td>\n",
       "      <td>0.772053</td>\n",
       "      <td>9088</td>\n",
       "      <td>9047</td>\n",
       "      <td>0.824513</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.840659</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Logistic Regression Lemm Count Ngrams</td>\n",
       "      <td>0.537549</td>\n",
       "      <td>0.537689</td>\n",
       "      <td>0.524162</td>\n",
       "      <td>0.826535</td>\n",
       "      <td>0.537430</td>\n",
       "      <td>6902</td>\n",
       "      <td>29855</td>\n",
       "      <td>0.498607</td>\n",
       "      <td>0.503425</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.494242</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes Stop Count TFIDF</td>\n",
       "      <td>0.804242</td>\n",
       "      <td>0.761356</td>\n",
       "      <td>0.769895</td>\n",
       "      <td>0.746870</td>\n",
       "      <td>0.761385</td>\n",
       "      <td>10089</td>\n",
       "      <td>8897</td>\n",
       "      <td>0.791086</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.791240</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVC Stop TFIDF No CV</td>\n",
       "      <td>0.836421</td>\n",
       "      <td>0.772355</td>\n",
       "      <td>0.766901</td>\n",
       "      <td>0.783852</td>\n",
       "      <td>0.772332</td>\n",
       "      <td>8615</td>\n",
       "      <td>9496</td>\n",
       "      <td>0.791086</td>\n",
       "      <td>0.783069</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.790774</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes Stop TFIDF No CV</td>\n",
       "      <td>0.804242</td>\n",
       "      <td>0.761356</td>\n",
       "      <td>0.769895</td>\n",
       "      <td>0.746870</td>\n",
       "      <td>0.761385</td>\n",
       "      <td>10089</td>\n",
       "      <td>8897</td>\n",
       "      <td>0.791086</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.791240</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random Forest Lemm TFIDF Ngrams</td>\n",
       "      <td>0.751415</td>\n",
       "      <td>0.742576</td>\n",
       "      <td>0.736917</td>\n",
       "      <td>0.755234</td>\n",
       "      <td>0.742565</td>\n",
       "      <td>9739</td>\n",
       "      <td>10728</td>\n",
       "      <td>0.785515</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.785202</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Random Forest stop TFIDF Ngrams Trimmed</td>\n",
       "      <td>0.753032</td>\n",
       "      <td>0.744953</td>\n",
       "      <td>0.744661</td>\n",
       "      <td>0.747071</td>\n",
       "      <td>0.744949</td>\n",
       "      <td>10081</td>\n",
       "      <td>10210</td>\n",
       "      <td>0.791086</td>\n",
       "      <td>0.771574</td>\n",
       "      <td>0.835165</td>\n",
       "      <td>0.790464</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Random Forest stop TFIDF Ngrams More Estimators</td>\n",
       "      <td>0.754808</td>\n",
       "      <td>0.747945</td>\n",
       "      <td>0.747798</td>\n",
       "      <td>0.749730</td>\n",
       "      <td>0.747941</td>\n",
       "      <td>9975</td>\n",
       "      <td>10078</td>\n",
       "      <td>0.782730</td>\n",
       "      <td>0.776596</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.782455</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVC Stop TFIDF Ngrams Limited</td>\n",
       "      <td>0.810126</td>\n",
       "      <td>0.783504</td>\n",
       "      <td>0.772496</td>\n",
       "      <td>0.804903</td>\n",
       "      <td>0.783462</td>\n",
       "      <td>7776</td>\n",
       "      <td>9448</td>\n",
       "      <td>0.818942</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.818945</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Random Forest Lemm TFIDF Ngrams Limited</td>\n",
       "      <td>0.741030</td>\n",
       "      <td>0.737105</td>\n",
       "      <td>0.733213</td>\n",
       "      <td>0.746186</td>\n",
       "      <td>0.737097</td>\n",
       "      <td>10099</td>\n",
       "      <td>10803</td>\n",
       "      <td>0.760446</td>\n",
       "      <td>0.752632</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.760089</td>\n",
       "      <td>39</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Random Forest stop TFIDF Ngrams</td>\n",
       "      <td>0.754218</td>\n",
       "      <td>0.744928</td>\n",
       "      <td>0.745730</td>\n",
       "      <td>0.744813</td>\n",
       "      <td>0.744928</td>\n",
       "      <td>10171</td>\n",
       "      <td>10122</td>\n",
       "      <td>0.782730</td>\n",
       "      <td>0.776596</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.782455</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random Forest Lemm TFIDF Ngrams More Estimators</td>\n",
       "      <td>0.749916</td>\n",
       "      <td>0.744438</td>\n",
       "      <td>0.741948</td>\n",
       "      <td>0.750283</td>\n",
       "      <td>0.744432</td>\n",
       "      <td>9936</td>\n",
       "      <td>10383</td>\n",
       "      <td>0.802228</td>\n",
       "      <td>0.790576</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.801841</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVC Lemm TFIDF No CV</td>\n",
       "      <td>0.827846</td>\n",
       "      <td>0.764297</td>\n",
       "      <td>0.756376</td>\n",
       "      <td>0.780366</td>\n",
       "      <td>0.764283</td>\n",
       "      <td>8739</td>\n",
       "      <td>10001</td>\n",
       "      <td>0.777159</td>\n",
       "      <td>0.771277</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.776883</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SVC Lemm TFIDF Ngrams Limited</td>\n",
       "      <td>0.799517</td>\n",
       "      <td>0.775441</td>\n",
       "      <td>0.762827</td>\n",
       "      <td>0.800020</td>\n",
       "      <td>0.775419</td>\n",
       "      <td>7957</td>\n",
       "      <td>9897</td>\n",
       "      <td>0.807799</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.807879</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SVC Lemm TFIDF Ngrams</td>\n",
       "      <td>0.800168</td>\n",
       "      <td>0.777240</td>\n",
       "      <td>0.763524</td>\n",
       "      <td>0.803840</td>\n",
       "      <td>0.777216</td>\n",
       "      <td>7805</td>\n",
       "      <td>9906</td>\n",
       "      <td>0.816156</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.816120</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Random Forest stop TFIDF Ngrams Limited</td>\n",
       "      <td>0.753089</td>\n",
       "      <td>0.746902</td>\n",
       "      <td>0.746125</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.746896</td>\n",
       "      <td>9965</td>\n",
       "      <td>10171</td>\n",
       "      <td>0.788301</td>\n",
       "      <td>0.781915</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.788027</td>\n",
       "      <td>35</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Logistic Regression Lemm TFIDF Ngrams Limited</td>\n",
       "      <td>0.798120</td>\n",
       "      <td>0.780912</td>\n",
       "      <td>0.770600</td>\n",
       "      <td>0.800523</td>\n",
       "      <td>0.780895</td>\n",
       "      <td>7937</td>\n",
       "      <td>9482</td>\n",
       "      <td>0.816156</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.815965</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVC Stop TFIDF Ngrams</td>\n",
       "      <td>0.801818</td>\n",
       "      <td>0.784974</td>\n",
       "      <td>0.773332</td>\n",
       "      <td>0.807462</td>\n",
       "      <td>0.784930</td>\n",
       "      <td>7674</td>\n",
       "      <td>9433</td>\n",
       "      <td>0.807799</td>\n",
       "      <td>0.802139</td>\n",
       "      <td>0.824176</td>\n",
       "      <td>0.807568</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Logistic Regression Lemm TFIDF No CV</td>\n",
       "      <td>0.795973</td>\n",
       "      <td>0.769794</td>\n",
       "      <td>0.761247</td>\n",
       "      <td>0.786750</td>\n",
       "      <td>0.769779</td>\n",
       "      <td>8485</td>\n",
       "      <td>9818</td>\n",
       "      <td>0.791086</td>\n",
       "      <td>0.792350</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.791007</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes Stop TFIDF Vectorizer</td>\n",
       "      <td>0.768037</td>\n",
       "      <td>0.760816</td>\n",
       "      <td>0.763352</td>\n",
       "      <td>0.757358</td>\n",
       "      <td>0.760823</td>\n",
       "      <td>9671</td>\n",
       "      <td>9358</td>\n",
       "      <td>0.799443</td>\n",
       "      <td>0.819767</td>\n",
       "      <td>0.774725</td>\n",
       "      <td>0.799792</td>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Logistic Regression Lemm TFIDF Ngrams</td>\n",
       "      <td>0.798120</td>\n",
       "      <td>0.780912</td>\n",
       "      <td>0.770600</td>\n",
       "      <td>0.800523</td>\n",
       "      <td>0.780895</td>\n",
       "      <td>7937</td>\n",
       "      <td>9482</td>\n",
       "      <td>0.816156</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.815965</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression Lemm TFIDF No CV</td>\n",
       "      <td>0.803713</td>\n",
       "      <td>0.779218</td>\n",
       "      <td>0.772372</td>\n",
       "      <td>0.793010</td>\n",
       "      <td>0.779191</td>\n",
       "      <td>8250</td>\n",
       "      <td>9315</td>\n",
       "      <td>0.782730</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.782610</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes Lemm TFIDF No CV</td>\n",
       "      <td>0.797187</td>\n",
       "      <td>0.754500</td>\n",
       "      <td>0.760192</td>\n",
       "      <td>0.744201</td>\n",
       "      <td>0.754509</td>\n",
       "      <td>10178</td>\n",
       "      <td>9341</td>\n",
       "      <td>0.791086</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.791395</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naive Bayes Lemm TFIDF Trigrams</td>\n",
       "      <td>0.760081</td>\n",
       "      <td>0.754210</td>\n",
       "      <td>0.754814</td>\n",
       "      <td>0.753676</td>\n",
       "      <td>0.754211</td>\n",
       "      <td>9801</td>\n",
       "      <td>9741</td>\n",
       "      <td>0.796657</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.796890</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes Lemm TFIDF Ngrams</td>\n",
       "      <td>0.776048</td>\n",
       "      <td>0.764159</td>\n",
       "      <td>0.763067</td>\n",
       "      <td>0.766845</td>\n",
       "      <td>0.764157</td>\n",
       "      <td>9277</td>\n",
       "      <td>9474</td>\n",
       "      <td>0.813370</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.813451</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Naive Bayes Lemm TFIDF Vectorizer</td>\n",
       "      <td>0.760081</td>\n",
       "      <td>0.754210</td>\n",
       "      <td>0.754814</td>\n",
       "      <td>0.753676</td>\n",
       "      <td>0.754211</td>\n",
       "      <td>9801</td>\n",
       "      <td>9741</td>\n",
       "      <td>0.796657</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.796890</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes Lemm Count TFIDF</td>\n",
       "      <td>0.797187</td>\n",
       "      <td>0.754500</td>\n",
       "      <td>0.760192</td>\n",
       "      <td>0.744201</td>\n",
       "      <td>0.754509</td>\n",
       "      <td>10178</td>\n",
       "      <td>9341</td>\n",
       "      <td>0.791086</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.791395</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes Stop TFIDF Trigrams</td>\n",
       "      <td>0.767990</td>\n",
       "      <td>0.760841</td>\n",
       "      <td>0.763351</td>\n",
       "      <td>0.757433</td>\n",
       "      <td>0.760848</td>\n",
       "      <td>9668</td>\n",
       "      <td>9359</td>\n",
       "      <td>0.799443</td>\n",
       "      <td>0.819767</td>\n",
       "      <td>0.774725</td>\n",
       "      <td>0.799792</td>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Random Forest Lemm TFIDF Ngrams Trimmed</td>\n",
       "      <td>0.750700</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.740162</td>\n",
       "      <td>0.754430</td>\n",
       "      <td>0.744555</td>\n",
       "      <td>9771</td>\n",
       "      <td>10538</td>\n",
       "      <td>0.785515</td>\n",
       "      <td>0.774869</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name  accuracy_train  \\\n",
       "10            Logistic Regression Stop TFIDF Ngrams        0.808545   \n",
       "11    Logistic Regression Stop TFIDF Ngrams Limited        0.806642   \n",
       "2                     Naive Bayes Stop TFIDF Ngrams        0.783524   \n",
       "13            Logistic Regression Lemm Count Ngrams        0.537549   \n",
       "0                      Naive Bayes Stop Count TFIDF        0.804242   \n",
       "19                             SVC Stop TFIDF No CV        0.836421   \n",
       "4                      Naive Bayes Stop TFIDF No CV        0.804242   \n",
       "27                  Random Forest Lemm TFIDF Ngrams        0.751415   \n",
       "26          Random Forest stop TFIDF Ngrams Trimmed        0.753032   \n",
       "25  Random Forest stop TFIDF Ngrams More Estimators        0.754808   \n",
       "18                    SVC Stop TFIDF Ngrams Limited        0.810126   \n",
       "28          Random Forest Lemm TFIDF Ngrams Limited        0.741030   \n",
       "23                  Random Forest stop TFIDF Ngrams        0.754218   \n",
       "29  Random Forest Lemm TFIDF Ngrams More Estimators        0.749916   \n",
       "22                             SVC Lemm TFIDF No CV        0.827846   \n",
       "21                    SVC Lemm TFIDF Ngrams Limited        0.799517   \n",
       "20                            SVC Lemm TFIDF Ngrams        0.800168   \n",
       "24          Random Forest stop TFIDF Ngrams Limited        0.753089   \n",
       "15    Logistic Regression Lemm TFIDF Ngrams Limited        0.798120   \n",
       "17                            SVC Stop TFIDF Ngrams        0.801818   \n",
       "16             Logistic Regression Lemm TFIDF No CV        0.795973   \n",
       "1                 Naive Bayes Stop TFIDF Vectorizer        0.768037   \n",
       "14            Logistic Regression Lemm TFIDF Ngrams        0.798120   \n",
       "12             Logistic Regression Lemm TFIDF No CV        0.803713   \n",
       "9                      Naive Bayes Lemm TFIDF No CV        0.797187   \n",
       "8                   Naive Bayes Lemm TFIDF Trigrams        0.760081   \n",
       "7                     Naive Bayes Lemm TFIDF Ngrams        0.776048   \n",
       "6                 Naive Bayes Lemm TFIDF Vectorizer        0.760081   \n",
       "5                      Naive Bayes Lemm Count TFIDF        0.797187   \n",
       "3                   Naive Bayes Stop TFIDF Trigrams        0.767990   \n",
       "30          Random Forest Lemm TFIDF Ngrams Trimmed        0.750700   \n",
       "\n",
       "    accuracy_test  precision_test  recall_test  roc_test  fn_test  fp_test  \\\n",
       "10       0.785264        0.777469     0.800487  0.785234     7952     9132   \n",
       "11       0.788695        0.780734     0.804024  0.788665     7811     9000   \n",
       "2        0.772053        0.772780     0.771985  0.772053     9088     9047   \n",
       "13       0.537689        0.524162     0.826535  0.537430     6902    29855   \n",
       "0        0.761356        0.769895     0.746870  0.761385    10089     8897   \n",
       "19       0.772355        0.766901     0.783852  0.772332     8615     9496   \n",
       "4        0.761356        0.769895     0.746870  0.761385    10089     8897   \n",
       "27       0.742576        0.736917     0.755234  0.742565     9739    10728   \n",
       "26       0.744953        0.744661     0.747071  0.744949    10081    10210   \n",
       "25       0.747945        0.747798     0.749730  0.747941     9975    10078   \n",
       "18       0.783504        0.772496     0.804903  0.783462     7776     9448   \n",
       "28       0.737105        0.733213     0.746186  0.737097    10099    10803   \n",
       "23       0.744928        0.745730     0.744813  0.744928    10171    10122   \n",
       "29       0.744438        0.741948     0.750283  0.744432     9936    10383   \n",
       "22       0.764297        0.756376     0.780366  0.764283     8739    10001   \n",
       "21       0.775441        0.762827     0.800020  0.775419     7957     9897   \n",
       "20       0.777240        0.763524     0.803840  0.777216     7805     9906   \n",
       "24       0.746902        0.746125     0.749981  0.746896     9965    10171   \n",
       "15       0.780912        0.770600     0.800523  0.780895     7937     9482   \n",
       "17       0.784974        0.773332     0.807462  0.784930     7674     9433   \n",
       "16       0.769794        0.761247     0.786750  0.769779     8485     9818   \n",
       "1        0.760816        0.763352     0.757358  0.760823     9671     9358   \n",
       "14       0.780912        0.770600     0.800523  0.780895     7937     9482   \n",
       "12       0.779218        0.772372     0.793010  0.779191     8250     9315   \n",
       "9        0.754500        0.760192     0.744201  0.754509    10178     9341   \n",
       "8        0.754210        0.754814     0.753676  0.754211     9801     9741   \n",
       "7        0.764159        0.763067     0.766845  0.764157     9277     9474   \n",
       "6        0.754210        0.754814     0.753676  0.754211     9801     9741   \n",
       "5        0.754500        0.760192     0.744201  0.754509    10178     9341   \n",
       "3        0.760841        0.763351     0.757433  0.760848     9668     9359   \n",
       "30       0.744563        0.740162     0.754430  0.744555     9771    10538   \n",
       "\n",
       "    accuracy_val  precision_val  recall_val   roc_val  fn_val  fp_val  score  \n",
       "10      0.832869       0.838889    0.829670  0.832914      31      29      4  \n",
       "11      0.824513       0.828729    0.824176  0.824517      32      31      3  \n",
       "2       0.824513       0.818182    0.840659  0.824284      29      34      2  \n",
       "13      0.498607       0.503425    0.807692  0.494242      35     145      2  \n",
       "0       0.791086       0.802260    0.780220  0.791240      40      35      1  \n",
       "19      0.791086       0.783069    0.813187  0.790774      34      41      1  \n",
       "4       0.791086       0.802260    0.780220  0.791240      40      35      1  \n",
       "27      0.785515       0.777778    0.807692  0.785202      35      42      0  \n",
       "26      0.791086       0.771574    0.835165  0.790464      30      45      0  \n",
       "25      0.782730       0.776596    0.802198  0.782455      36      42      0  \n",
       "18      0.818942       0.823204    0.818681  0.818945      33      32      0  \n",
       "28      0.760446       0.752632    0.785714  0.760089      39      47      0  \n",
       "23      0.782730       0.776596    0.802198  0.782455      36      42      0  \n",
       "29      0.802228       0.790576    0.829670  0.801841      31      40      0  \n",
       "22      0.777159       0.771277    0.796703  0.776883      37      43      0  \n",
       "21      0.807799       0.815642    0.802198  0.807879      36      33      0  \n",
       "20      0.816156       0.818681    0.818681  0.816120      33      33      0  \n",
       "24      0.788301       0.781915    0.807692  0.788027      35      41      0  \n",
       "15      0.816156       0.811828    0.829670  0.815965      31      35      0  \n",
       "17      0.807799       0.802139    0.824176  0.807568      32      37      0  \n",
       "16      0.791086       0.792350    0.796703  0.791007      37      38      0  \n",
       "1       0.799443       0.819767    0.774725  0.799792      41      31      0  \n",
       "14      0.816156       0.811828    0.829670  0.815965      31      35      0  \n",
       "12      0.782730       0.782609    0.791209  0.782610      38      40      0  \n",
       "9       0.791086       0.809249    0.769231  0.791395      42      33      0  \n",
       "8       0.796657       0.811429    0.780220  0.796890      40      33      0  \n",
       "7       0.813370       0.821229    0.807692  0.813451      35      32      0  \n",
       "6       0.796657       0.811429    0.780220  0.796890      40      33      0  \n",
       "5       0.791086       0.809249    0.769231  0.791395      42      33      0  \n",
       "3       0.799443       0.819767    0.774725  0.799792      41      31      0  \n",
       "30      0.785515       0.774869    0.813187  0.785124      34      43      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidePrompt": true
   },
   "source": [
    "A scoring (column named score above) was done to view the best models. If the model had the highest training accuracy, test accuracy, validation accuracy, precision, recall, or AUC, then the model got a score of 1 for each category. If the model had the minimum of false negatives and false positives, then the model got a score of 1 for each category where it was a minimum.\n",
    "\n",
    "The best performing models were all Logistic Regression Models that used Ngrams and TFIDF and a Naive Bayes model without lemmatized words and TFIDF. The final model chosen was the Logistic Regression without lemmatized words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## C. Final Model\n",
    "The final model, Logistic Regression without Lemmatized Words and TFIDF, was chosen because the model did the best when it came to false positives and false negatives in the testing set. It also had high values for precision and recall and performed just as well as the other models when it came to the validation set.\n",
    "\n",
    "The print out below shows the positive words from the model and the negative words for the model. This was done by predicting the positivity of the words that were used to build the model. The only word that sticks out in the two lists is fuzzball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative words and phrases\n",
      "            miss sad 0.00\n",
      "                 sad 0.00\n",
      "        sad happened 0.00\n",
      "           sad alone 0.00\n",
      "            sad miss 0.00\n",
      "            died sad 0.00\n",
      "           hours sad 0.00\n",
      "            sad last 0.00\n",
      "         sad morning 0.00\n",
      "              bummed 0.00\n",
      "             sad day 0.00\n",
      "            sad wish 0.00\n",
      "               sadly 0.00\n",
      "        gutted didnt 0.00\n",
      "           miss cant 0.00\n",
      "___________________________\n",
      "Positive words and phrases\n",
      "         loving life 1.00\n",
      "           glad love 1.00\n",
      "           yay thank 1.00\n",
      "             welcome 1.00\n",
      "          proud haha 1.00\n",
      "         thanks glad 1.00\n",
      " yay congratulations 1.00\n",
      "          thank glad 1.00\n",
      "           thank yes 1.00\n",
      "           big smile 1.00\n",
      "         smile happy 1.00\n",
      "          thank haha 1.00\n",
      "        welcome glad 1.00\n",
      "              smilin 1.00\n",
      "            fuzzball 1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Negative words and phrases\")\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(p))\n",
    "print('___________________________')\n",
    "print(\"Positive words and phrases\")\n",
    "for w, p in zip(bad_words, bad_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidePrompt": true
   },
   "source": [
    "# V. Additional Work\n",
    "Additional word can be done on this project to improve the results. Instead of removing all emojis, the emojis that show emotion (smiley faces, angry faces, etc.) could be parsed into text. There are still thousands of tweets that contain spelling errors and additional corrections can be done. Words could also potentially be stemmed, reducing words to their root word, to see if that improves the accuracy of the models. In addition to those changes, the hashtags could be kept to see how they effect the model's performance.\n",
    "\n",
    "The tweets are all mostly positive for the NHL teams. I could collect the tweets again and in a more targeted fashion, like just looking for the replies to the team accounts. Those tweets, from what I've witnessed, seem to be a mixed bag of positive and negative. The biggest change to make would be to collect hockey related tweets and classify them to build a model off of those. The models in the report above were based on generic tweets and were not hockey specific.\n",
    "\n",
    "### Packages Used\n",
    "Python3.6, Pandas, Numpy, NLTK, Scikit Learn, WordCloud, Matplotlib, Seaborn, Gensim\n",
    "\n",
    "### Models Used\n",
    "Naive Bayes, Logistic Regression, Linear Support Vector Machine, Random Forests, Word2Vec, Ngrams, Count Vectorization, and TFIDF\n",
    "\n",
    "#### References\n",
    "[Sentiment140 pre-classified tweets](http://help.sentiment140.com/for-students)\n",
    "<br>\n",
    "[NHL Team Logos](http://www.sportslogos.net/teams/list_by_league/1/National_Hockey_League/NHL/logos)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
