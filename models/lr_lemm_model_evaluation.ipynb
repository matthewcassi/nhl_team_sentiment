{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/matthewcassi/Documents/nhl_sentiment_working/sentiment_data/none/lemm_training.csv')\n",
    "testing = pd.read_csv('/Users/matthewcassi/Documents/nhl_sentiment_working/sentiment_data/none/lemm_testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 0', 1, inplace=True)\n",
    "testing.drop('Unnamed: 0', 1, inplace=True)\n",
    "data = data.dropna()\n",
    "testing = testing.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_y = data['sentiment']\n",
    "data_x = data['lemm_text']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=.05, random_state=232)\n",
    "\n",
    "test_y = testing['sentiment']\n",
    "test_x = testing['lemm_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_1 = 'Logistic Regression Lemm Count Ngrams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_lemm_count_ngrams = joblib.load('lr_lemm_count_ngrams.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_1 = lr_lemm_count_ngrams.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_1 = lr_lemm_count_ngrams.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_1 = accuracy_score(y_test, pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.25      0.35     39718\n",
      "          1       0.52      0.83      0.64     39789\n",
      "\n",
      "avg / total       0.56      0.54      0.50     79507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_1 = precision_score(y_test, pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_1 = recall_score(y_test, pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tn1, fp1, fn1, tp1 = confusion_matrix(y_test, pred_1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_1 = roc_auc_score(y_test, pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_11 = lr_lemm_count_ngrams.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_11 = accuracy_score(test_y, pred_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_11 = precision_score(test_y, pred_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_11 = recall_score(test_y, pred_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tn11, fp11, fn11, tp11 = confusion_matrix(test_y, pred_11).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.18      0.26       177\n",
      "          1       0.50      0.81      0.62       182\n",
      "\n",
      "avg / total       0.49      0.50      0.44       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roc_11 = roc_auc_score(test_y, pred_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Logistic Regression Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_2 = 'Logistic Regression Lemm TFIDF Ngrams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_lemm_tfidf_vec_ngrams = joblib.load('lr_lemm_tfidf_vec_ngrams.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_2 = lr_lemm_tfidf_vec_ngrams.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_2 = lr_lemm_tfidf_vec_ngrams.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_2 = accuracy_score(y_test, pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tn2, fp2, fn2, tp2 = confusion_matrix(y_test, pred_2).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.76      0.78     39718\n",
      "          1       0.77      0.80      0.79     39789\n",
      "\n",
      "avg / total       0.78      0.78      0.78     79507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_2 = precision_score(y_test, pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_2 = recall_score(y_test, pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_2 = roc_auc_score(y_test, pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_22 = lr_lemm_tfidf_vec_ngrams.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_22 = accuracy_score(test_y, pred_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tn22, fp22, fn22, tp22 = confusion_matrix(test_y, pred_22).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.80      0.81       177\n",
      "          1       0.81      0.83      0.82       182\n",
      "\n",
      "avg / total       0.82      0.82      0.82       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_22 = precision_score(test_y, pred_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_22 = recall_score(test_y, pred_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roc_22 = roc_auc_score(test_y, pred_22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_3 = 'Logistic Regression Lemm TFIDF Ngrams Limited'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_lemm_tfidf_vec_ngrams_limited = joblib.load('lr_lemm_tfidf_vec_ngrams_limited.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_3 = lr_lemm_tfidf_vec_ngrams_limited.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_3 = lr_lemm_tfidf_vec_ngrams_limited.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_3 = accuracy_score(y_test, pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tn3, fp3, fn3, tp3 = confusion_matrix(y_test, pred_3).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.76      0.78     39718\n",
      "          1       0.77      0.80      0.79     39789\n",
      "\n",
      "avg / total       0.78      0.78      0.78     79507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_3 = precision_score(y_test, pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_3 = recall_score(y_test, pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_3 = roc_auc_score(y_test, pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_33 = lr_lemm_tfidf_vec_ngrams_limited.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_33 = accuracy_score(test_y, pred_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tn33, fp33, fn33, tp33 = confusion_matrix(test_y, pred_33).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.80      0.81       177\n",
      "          1       0.81      0.83      0.82       182\n",
      "\n",
      "avg / total       0.82      0.82      0.82       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_33 = precision_score(test_y, pred_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_33 = recall_score(test_y, pred_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roc_33 = roc_auc_score(test_y, pred_33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Logistic Regression Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_4 = 'Logistic Regression Lemm TFIDF No CV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_lemm_tfidf_vec_nocv = joblib.load('lr_lemm_tfidf_vec_nocv.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_4 = lr_lemm_tfidf_vec_nocv.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_4 = lr_lemm_tfidf_vec_nocv.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_4 = accuracy_score(y_test, pred_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tn4, fp4, fn4, tp4 =confusion_matrix(y_test, pred_4).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.75      0.77     39718\n",
      "          1       0.76      0.79      0.77     39789\n",
      "\n",
      "avg / total       0.77      0.77      0.77     79507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_4 = precision_score(y_test, pred_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_4 = recall_score(y_test, pred_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_4 = roc_auc_score(y_test, pred_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_44 = lr_lemm_tfidf_vec_nocv.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_44 = accuracy_score(test_y, pred_44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tn44, fp44, fn44, tp44 = confusion_matrix(test_y, pred_44).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.79      0.79       177\n",
      "          1       0.79      0.80      0.79       182\n",
      "\n",
      "avg / total       0.79      0.79      0.79       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_44))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_44 = precision_score(test_y, pred_44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_44 = recall_score(test_y, pred_44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roc_44 = roc_auc_score(test_y, pred_44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_dict = {\n",
    "    'name': [name_1, name_2, name_3, name_4],\n",
    "    'acc_train':[train_1, train_2, train_3, train_4],\n",
    "    'acc_test':[acc_1,acc_2,acc_3,acc_4],\n",
    "    'roc_acc':[roc_1,roc_2,roc_3,roc_4],\n",
    "    'precision_test':[precision_1,precision_2,precision_3,precision_4],\n",
    "    'recall_test':[recall_1,recall_2,recall_3,recall_4],\n",
    "    'fn_test': [fn1, fn2, fn3, fn4],\n",
    "    'fp_test': [fp1, fp2, fp3, fp4],\n",
    "    'acc_val':[acc_11,acc_22,acc_33,acc_44],\n",
    "    'roc_val':[roc_11,roc_22,roc_33,roc_44],\n",
    "    'precision_val':[precision_11,precision_22,precision_33,precision_44],\n",
    "    'recall_val':[recall_11,recall_22,recall_33,recall_44],\n",
    "    'fn_val': [fn11, fn22, fn33, fn44],\n",
    "    'fp_val': [fp11, fp22, fp33, fp44]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(score_dict)\n",
    "scores.to_csv('lr_lemm_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
